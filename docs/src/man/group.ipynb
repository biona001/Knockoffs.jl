{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Knockoffs\n",
    "\n",
    "This tutorial generates group (model-X) knockoffs, which is useful when predictors are highly correlated. The methodology is described in the following paper\n",
    "\n",
    "> Dai R, Barber R. The knockoff filter for FDR control in group-sparse and multitask regression. InInternational conference on machine learning 2016 Jun 11 (pp. 1851-1859). PMLR.\n",
    "\n",
    "\n",
    "!!! note\n",
    "\n",
    "    In the original paper, Dai and Barber only describes how to construct a suboptimal equi-correlated group knockoffs. Here we implement fully generalized alternatives.\n",
    "    \n",
    "Currently available options for group knockoffs:\n",
    "+ `:mvr`: Fully general minimum variance-based reconstructability (MVR) group knockoff, based on coordinate descent.\n",
    "+ `:maxent`: Fully general maximum entropy (maxent) group knockoff, based on coordinate descent.\n",
    "+ `:equi`: This implements the equi-correlated idea proposed in [Barber and Dai](https://proceedings.mlr.press/v48/daia16.html), which lets $S_j = \\gamma \\Sigma_{(G_j, G_j)}$ where $\\Sigma_{(G_j, G_j)}$ is the block of $\\Sigma$ containing variables in the $j$th group. Thus, instead of optimizing over all variables in $S$, we optimize a scalar $\\gamma$. Conveniently, there a simple closed form solution for $\\gamma$. For `mvr` and `maxent` group knockoffs, we initialize $S$ using this construction. \n",
    "+ `:SDP`: This generalizes the equi-correlated group knockoff idea by having $S_j = \\gamma_j \\Sigma_{(G_j, G_j)}$. Instead of optimizing over all variables in $S$, we optimize over a vector $\\gamma_1,...,\\gamma_G$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_signif_groups (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load packages for this tutorial\n",
    "using Revise\n",
    "using Knockoffs\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using ToeplitzMatrices\n",
    "\n",
    "# some helper functions to compute power and empirical FDR\n",
    "function TP(correct_groups, signif_groups)\n",
    "    return length(signif_groups ∩ correct_groups) / length(correct_groups)\n",
    "end\n",
    "function TP(correct_groups, β̂, groups)\n",
    "    signif_groups = get_signif_groups(β̂, groups)\n",
    "    return TP(correct_groups, signif_groups)\n",
    "end\n",
    "function FDR(correct_groups, signif_groups)\n",
    "    FP = length(signif_groups) - length(signif_groups ∩ correct_groups) # number of false positives\n",
    "    FDR = FP / max(1, length(signif_groups))\n",
    "    return FDR\n",
    "end\n",
    "function FDR(correct_groups, β̂, groups)\n",
    "    signif_groups = get_signif_groups(β̂, groups)\n",
    "    return FDR(correct_groups, signif_groups)\n",
    "end\n",
    "function get_signif_groups(β, groups)\n",
    "    correct_groups = Int[]\n",
    "    for i in findall(!iszero, β)\n",
    "        g = groups[i]\n",
    "        g ∈ correct_groups || push!(correct_groups, g)\n",
    "    end\n",
    "    return correct_groups\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing group knockoffs\n",
    "\n",
    "First, let's simulate data and generate equi-correlated knockoffs. Our true covariance matrix looks like\n",
    "\n",
    "```math\n",
    "\\begin{aligned}\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "    1 & \\rho & \\rho^2 & ... & \\rho^p\\\\\n",
    "    \\rho & 1 & & ... & \\rho^{p-1}\\\\\n",
    "    \\vdots & & & 1 & \\vdots \\\\\n",
    "    \\rho^p & \\cdots & & & 1\n",
    "\\end{pmatrix}, \\quad \\rho = 0.9\n",
    "\\end{aligned}\n",
    "```\n",
    "\n",
    "Because variables are highly correlated with its neighbors ($\\rho = 0.9$), it becomes difficult to distinguish which variables among a group are truly causal. Thus, group knockoffs which test whether a *group* of variables have any signal should have better power than standard (single-variable) knockoffs. \n",
    "\n",
    "For simplicity, let simulate data where every 5 variables form a group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# simulate data\n",
    "Random.seed!(2022)\n",
    "n = 1000 # sample size\n",
    "p = 200  # number of covariates\n",
    "k = 10   # number of true predictors\n",
    "Σ = Matrix(SymmetricToeplitz(0.4.^(0:(p-1)))) # true covariance matrix\n",
    "groupsizes = [5 for i in 1:div(p, 5)] # each group has 5 variables\n",
    "groups = vcat([i*ones(g) for (i, g) in enumerate(groupsizes)]...) |> Vector{Int}\n",
    "true_mu = zeros(p)\n",
    "L = cholesky(Σ).L\n",
    "X = randn(n, p) * L\n",
    "zscore!(X, mean(X, dims=1), std(X, dims=1)); # standardize columns of X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate group knockoffs with the exported function `modelX_gaussian_group_knockoffs`. Similar to non-group knockoffs, group knockoff accepts keyword arguments `m`, `tol`, `niter`, and `verbose` which controls the algorithm's behavior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 1: δ = 0.35041635762964374, t1 = 0.07, t2 = 0.01, t3 = 0.0\n",
      "Iter 2: δ = 0.06174971923894666, t1 = 0.07, t2 = 0.02, t3 = 0.0\n",
      "Iter 3: δ = 0.020679713293120027, t1 = 0.08, t2 = 0.04, t3 = 0.0\n",
      "Iter 4: δ = 0.010800522507824841, t1 = 0.09, t2 = 0.05, t3 = 0.0\n",
      "Iter 5: δ = 0.006051906091741958, t1 = 0.09, t2 = 0.06, t3 = 0.0\n",
      "Iter 6: δ = 0.003458575128440409, t1 = 0.1, t2 = 0.07, t3 = 0.0\n",
      "Iter 7: δ = 0.0016285523099343307, t1 = 0.1, t2 = 0.09, t3 = 0.0\n",
      "Iter 8: δ = 0.0007940739052498399, t1 = 0.11, t2 = 0.1, t3 = 0.0\n",
      "Iter 9: δ = 0.0003768922472274655, t1 = 0.11, t2 = 0.11, t3 = 0.0\n",
      "Iter 10: δ = 0.00015544193550259136, t1 = 0.12, t2 = 0.12, t3 = 0.0\n",
      "Iter 11: δ = 0.00014451264472101048, t1 = 0.12, t2 = 0.14, t3 = 0.0\n",
      "Iter 12: δ = 3.6816774372557906e-5, t1 = 0.12, t2 = 0.15, t3 = 0.0\n"
     ]
    }
   ],
   "source": [
    "Gme = modelX_gaussian_group_knockoffs(\n",
    "    X, :maxent, groups, true_mu, Σ, \n",
    "    m = 1,          # number of knockoffs per variable to generate\n",
    "    tol = 0.0001,   # convergence tolerance\n",
    "    niter = 100,    # max number of coordinate descent iterations\n",
    "    verbose=true);  # whether to print informative intermediate results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note $t1, t2, t3$ are timers which corresponds to (1) updating cholesky factors, (2) solving forward-backward equations, and (3) solving off-diagonal 1D optimization problems using Brent's method. As we can see, the computational bottleneck in (2), which we dispatch to efficient LAPACK libraries. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is a struct with the following fields\n",
    "```julia\n",
    "struct GaussianGroupKnockoff{T<:AbstractFloat, BD<:AbstractMatrix, S<:Symmetric} <: Knockoff\n",
    "    X::Matrix{T} # n × p design matrix\n",
    "    X̃::Matrix{T} # n × p knockoff of X\n",
    "    groups::Vector{Int} # p × 1 vector of group membership\n",
    "    S::BD # p × p block-diagonal matrix of the same size as Σ. S and 2Σ - S are both psd\n",
    "    γs::Vector{T} # scalars chosen so that 2Σ - S is positive definite where S_i = γ_i * Σ_i\n",
    "    Σ::S # p × p symmetric covariance matrix. \n",
    "    method::Symbol # method for solving s\n",
    "end\n",
    "```\n",
    "Given this result, lets do a sanity check: is $2\\Sigma - S$ positive semi-definite?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.417481414774321"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compute minimum eigenvalues of 2Σ - S\n",
    "eigmin(2Gme.Σ - Gme.S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second order group knockoffs\n",
    "\n",
    "In practice, we often do not have the true covariance matrix $\\Sigma$ and the true means $\\mu$. In that case, we can generate second order group knockoffs via the 3 argument function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Gme_second_order = modelX_gaussian_group_knockoffs(X, :maxent, groups);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will estimate the covariance matrix via a shrinkage estimator, see documentation API for more details. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso Example\n",
    "\n",
    "Lets see the empirical power and FDR group knockoffs over 10 simulations when the targer FDR is 10%. Here power and FDR is defined at the group level. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sim 1 group-knockoff power = 0.0, FDR = 0.0, time=5.356796708\n",
      "Sim 2 group-knockoff power = 0.1, FDR = 0.0, time=3.846174709\n",
      "Sim 3 group-knockoff power = 0.222, FDR = 0.0, time=2.418540375\n",
      "Sim 4 group-knockoff power = 0.4, FDR = 0.2, time=3.774003875\n",
      "Sim 5 group-knockoff power = 0.4, FDR = 0.0, time=2.337522042\n",
      "Sim 6 group-knockoff power = 0.0, FDR = 0.0, time=3.913260458\n",
      "Sim 7 group-knockoff power = 0.222, FDR = 0.333, time=2.531130667\n",
      "Sim 8 group-knockoff power = 0.0, FDR = 0.0, time=3.927257125\n",
      "Sim 9 group-knockoff power = 0.0, FDR = 0.0, time=3.9803245\n",
      "Sim 10 group-knockoff power = 0.1, FDR = 0.0, time=2.300255291\n",
      "\n",
      "ME group knockoffs have average group power 0.1444\n",
      "ME group knockoffs have average group FDR 0.0533\n",
      "ME group knockoffs took average 3.438526575 seconds\n"
     ]
    }
   ],
   "source": [
    "target_fdr = 0.1\n",
    "group_powers, group_fdrs, group_times, group_s = Float64[], Float64[], Float64[], Float64[]\n",
    "\n",
    "Random.seed!(2022)\n",
    "for sim in 1:10\n",
    "    # simulate X\n",
    "    Random.seed!(sim)\n",
    "    n = 1000 # sample size\n",
    "    p = 200  # number of covariates\n",
    "    k = 10   # number of true predictors\n",
    "    Σ = Matrix(SymmetricToeplitz(0.9.^(0:(p-1)))) # true covariance matrix\n",
    "    groupsizes = [5 for i in 1:div(p, 5)] # each group has 5 variables\n",
    "    groups = vcat([i*ones(g) for (i, g) in enumerate(groupsizes)]...) |> Vector{Int}\n",
    "    true_mu = zeros(p)\n",
    "    L = cholesky(Σ).L\n",
    "    X = randn(n, p) * L\n",
    "    zscore!(X, mean(X, dims=1), std(X, dims=1)); # standardize columns of X\n",
    "\n",
    "    # simulate y\n",
    "    βtrue = zeros(p)\n",
    "    βtrue[1:k] .= rand(-1:2:1, k) .* 0.1\n",
    "    shuffle!(βtrue)\n",
    "    correct_groups = get_signif_groups(βtrue, groups)\n",
    "    ϵ = randn(n)\n",
    "    y = X * βtrue + ϵ;\n",
    "\n",
    "    # group MVR knockoffs\n",
    "    t = @elapsed ko_filter = fit_lasso(y, X, method=:maxent, groups=groups)\n",
    "    power = round(TP(correct_groups, ko_filter.βs[idx], groups), digits=3)\n",
    "    fdr = round(FDR(correct_groups, ko_filter.βs[idx], groups), digits=3)\n",
    "    println(\"Sim $sim group-knockoff power = $power, FDR = $fdr, time=$t\")\n",
    "    push!(group_powers, power); push!(group_fdrs, fdr); push!(group_times, t)\n",
    "    GC.gc();GC.gc();GC.gc();\n",
    "end\n",
    "\n",
    "println(\"\\nME group knockoffs have average group power $(mean(group_powers))\")\n",
    "println(\"ME group knockoffs have average group FDR $(mean(group_fdrs))\")\n",
    "println(\"ME group knockoffs took average $(mean(group_times)) seconds\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "+ When variables are highly correlated so that one cannot find exact discoveries, group knockoffs may be useful as it identifies whether a group of variables are non-null without having to pinpoint the exact discovery.\n",
    "+ Group knockoffs control the group FDR to be below the target FDR level. \n",
    "+ Groups do not have to be contiguous\n"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
