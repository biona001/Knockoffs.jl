{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare different ways of estimating covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Precompiling Knockoffs [878bf26d-0c49-448a-9df5-b057c815d613]\n",
      "└ @ Base loading.jl:1423\n"
     ]
    }
   ],
   "source": [
    "using Revise\n",
    "using Knockoffs\n",
    "using Test\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using StatsBase\n",
    "using Statistics\n",
    "using Distributions\n",
    "using ToeplitzMatrices\n",
    "using Plots\n",
    "using CovarianceEstimation\n",
    "gr(fmt=:png);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model is\n",
    "\n",
    "$$X_{p \\times 1} \\sim N(\\mathbf{0}_p, \\Sigma)$$\n",
    "where\n",
    "$$\n",
    "\\Sigma = \n",
    "\\begin{pmatrix}\n",
    "    1 & \\rho & \\rho^2 & ... & \\rho^p\\\\\n",
    "    \\rho & 1 & & ... & \\rho^{p-1}\\\\\n",
    "    \\vdots & & & 1 & \\vdots \\\\\n",
    "    \\rho^p & \\cdots & & & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "Given $n$ iid samples from the above distribution, we will generate knockoffs according to \n",
    "$$(X, \\tilde{X}) \\sim N\n",
    "\\left(0, \\ \n",
    "\\begin{pmatrix}\n",
    "    \\Sigma & \\Sigma - diag(s)\\\\\n",
    "    \\Sigma - diag(s) & \\Sigma\n",
    "\\end{pmatrix}\n",
    "\\right)\n",
    "$$\n",
    "where $s$ is solved so that $0 \\le s_j \\forall j$ and $G$ is PSD (i.e. $2Σ - diag(s)$ is PSD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "Random.seed!(2022)\n",
    "n = 100\n",
    "p = 500\n",
    "ρ = 0.4\n",
    "Sigma = Matrix(SymmetricToeplitz(ρ.^(0:(p-1))))\n",
    "L = cholesky(Sigma).L\n",
    "X = randn(n, p) * L # var(X) = L var(N(0, 1)) L' = var(Σ)\n",
    "true_mu = zeros(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $p > n$ case\n",
    "\n",
    "### LinearShrinkage via Ledoit Wolf with DiagonalUnequalVariance\n",
    "\n",
    "This is the default method recommended for $p>n$ case, see https://mateuszbaran.github.io/CovarianceEstimation.jl/dev/man/methods/#Comparing-estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.013680 seconds (33 allocations: 8.791 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Σapprox = cov(LinearShrinkage(DiagonalUnequalVariance(), :lw), X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearShrinkage via schaffer-strimmer with DiagonalCommonVariance\n",
    "\n",
    "This seems to give best MSE for various n/p combinations, as shown https://mateuszbaran.github.io/CovarianceEstimation.jl/dev/man/msecomp/#msecomp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.029732 seconds (39 allocations: 12.610 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Σapprox2 = cov(LinearShrinkage(DiagonalCommonVariance(), :ss), X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(Sigma .- Σapprox) = 13.672021076565523\n",
      "norm(Sigma .- Σapprox2) = 13.30716999433807\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250000×3 Matrix{Float64}:\n",
       " 1.0           0.807852      0.976725\n",
       " 0.4           0.0314039     0.0291557\n",
       " 0.16          0.0214846     0.0199465\n",
       " 0.064         0.00477416    0.00443238\n",
       " 0.0256        0.00428901    0.00398196\n",
       " 0.01024       0.00335206    0.00311209\n",
       " 0.004096      0.00786648    0.00730333\n",
       " 0.0016384     0.00759405    0.0070504\n",
       " 0.00065536    0.0122099     0.0113358\n",
       " 0.000262144  -0.00630362   -0.00585235\n",
       " 0.000104858   0.000187246   0.000173841\n",
       " 4.1943e-5    -0.0101748    -0.00944637\n",
       " 1.67772e-5   -0.00774287   -0.00718856\n",
       " ⋮                          \n",
       " 4.1943e-5    -0.00566428   -0.00525878\n",
       " 0.000104858  -0.00690351   -0.00640929\n",
       " 0.000262144   0.00579939    0.00538422\n",
       " 0.00065536   -0.00173785   -0.00161344\n",
       " 0.0016384    -0.00499857   -0.00464073\n",
       " 0.004096      0.0031627     0.00293628\n",
       " 0.01024       0.0101293     0.00940414\n",
       " 0.0256        0.00296201    0.00274996\n",
       " 0.064         0.00141277    0.00131163\n",
       " 0.16          0.0184645     0.0171427\n",
       " 0.4           0.0244281     0.0226793\n",
       " 1.0           0.720507      0.969905"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare estimates to truth\n",
    "@show norm(Sigma .- Σapprox)\n",
    "@show norm(Sigma .- Σapprox2)\n",
    "[vec(Sigma) vec(Σapprox) vec(Σapprox2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $n > p$ case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate data\n",
    "Random.seed!(2022)\n",
    "n = 1000\n",
    "p = 500\n",
    "ρ = 0.4\n",
    "Sigma = Matrix(SymmetricToeplitz(ρ.^(0:(p-1))))\n",
    "L = cholesky(Sigma).L\n",
    "X = randn(n, p) * L # var(X) = L var(N(0, 1)) L' = var(Σ)\n",
    "\n",
    "# simulate data (this data shows Analytical Non-linear shrinkage can do poorly)\n",
    "# Random.seed!(2022)\n",
    "# n = 1000\n",
    "# p = 500\n",
    "# ρ = 0.4\n",
    "# Sigma = (1-ρ)I + ρ .* ones((p, p))\n",
    "# L = cholesky(Sigma).L\n",
    "# X = randn(n, p) * L # var(X) = L var(N(0, 1)) L' = var(Σ)\n",
    "# true_mu = zeros(p);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearShrinkage via Ledoit Wolf with DiagonalUnequalVariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.036899 seconds (33 allocations: 19.091 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Σapprox = cov(LinearShrinkage(DiagonalUnequalVariance(), :lw), X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LinearShrinkage via schaffer-strimmer with DiagonalCommonVariance\n",
    "This seems to give best MSE for $p>n$ case (see above). Lets see how it performs in $n>p$ case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.073585 seconds (39 allocations: 22.910 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Σapprox2 = cov(LinearShrinkage(DiagonalCommonVariance(), :ss), X);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytical Non-linear shrinkage \n",
    "\n",
    "This sometimes perform worse and is slow in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.150961 seconds (123 allocations: 28.860 MiB)\n"
     ]
    }
   ],
   "source": [
    "@time Σapprox3 = cov(AnalyticalNonlinearShrinkage(), X);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm(Sigma .- Σapprox) = 10.419794517086471\n",
      "norm(Sigma .- Σapprox2) = 10.375954445137257\n",
      "norm(Sigma .- Σapprox3) = 10.305885983875836\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "250000×4 Matrix{Float64}:\n",
       " 1.0           1.09108      1.04167      1.04947\n",
       " 0.4           0.18855      0.187167     0.204735\n",
       " 0.16          0.065677     0.0651952    0.0702049\n",
       " 0.064         0.0134579    0.0133592    0.0133384\n",
       " 0.0256        0.0135339    0.0134346    0.0133853\n",
       " 0.01024       0.0171558    0.01703      0.0180576\n",
       " 0.004096     -0.00358494  -0.00355865  -0.00215183\n",
       " 0.0016384    -0.0257009   -0.0255124   -0.0243957\n",
       " 0.00065536   -0.0287337   -0.0285229   -0.0301445\n",
       " 0.000262144  -0.0153974   -0.0152844   -0.0114235\n",
       " 0.000104858  -0.00758369  -0.00752806  -0.00540316\n",
       " 4.1943e-5    -0.0191237   -0.0189834   -0.0205698\n",
       " 1.67772e-5    0.00725894   0.0072057    0.00761886\n",
       " ⋮                                      \n",
       " 4.1943e-5     0.0170714    0.0169462    0.0191543\n",
       " 0.000104858   0.00506735   0.00503019   0.00385539\n",
       " 0.000262144   0.00256931   0.00255046   0.00274609\n",
       " 0.00065536   -0.0024898   -0.00247154  -0.00410855\n",
       " 0.0016384     0.0142631    0.0141585    0.0133332\n",
       " 0.004096     -0.0209935   -0.0208395   -0.0226539\n",
       " 0.01024      -0.00884027  -0.00877543  -0.0115733\n",
       " 0.0256        0.0178637    0.0177326    0.0167558\n",
       " 0.064         0.0242134    0.0240358    0.024765\n",
       " 0.16          0.0497468    0.0493819    0.0561205\n",
       " 0.4           0.127587     0.126651     0.141566\n",
       " 1.0           0.800538     0.916024     0.910166"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare estimates to truth\n",
    "@show norm(Sigma .- Σapprox)\n",
    "@show norm(Sigma .- Σapprox2)\n",
    "@show norm(Sigma .- Σapprox3)\n",
    "[vec(Sigma) vec(Σapprox) vec(Σapprox2) vec(Σapprox3)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion: \n",
    "\n",
    "`LinearShrinkage(DiagonalCommonVariance(), :ss)` seems to perform best in general for both $p>n$ and $n>p$ case, and is pretty fast in general"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
