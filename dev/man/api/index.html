<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>API · Knockoffs.jl</title><meta name="title" content="API · Knockoffs.jl"/><meta property="og:title" content="API · Knockoffs.jl"/><meta property="twitter:title" content="API · Knockoffs.jl"/><meta name="description" content="Documentation for Knockoffs.jl."/><meta property="og:description" content="Documentation for Knockoffs.jl."/><meta property="twitter:description" content="Documentation for Knockoffs.jl."/><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../search_index.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Knockoffs.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../fixed/fixed/">Fixed-X Knockoffs</a></li><li><a class="tocitem" href="../modelX/modelX/">Model-X Knockoffs</a></li><li><a class="tocitem" href="../group/">Group Knockoffs</a></li><li><a class="tocitem" href="../knockoffscreen/knockoffscreen/">KnockoffScreen Knockoffs</a></li><li><a class="tocitem" href="../ghost_knockoffs/">Ghost Knockoffs</a></li><li><a class="tocitem" href="../hmm/hmm/">HMM Knockoffs</a></li><li><a class="tocitem" href="../ipad/">IPAD Knockoffs</a></li><li><a class="tocitem" href="../JuliaCall/">Calling from R/Python</a></li><li class="is-active"><a class="tocitem" href>API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>API</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/biona001/Knockoffs.jl" title="View the repository on GitHub"><span class="docs-icon fa-brands"></span><span class="docs-label is-hidden-touch">GitHub</span></a><a class="docs-navbar-link" href="https://github.com/biona001/Knockoffs.jl/blob/master/docs/src/man/api.md" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="API"><a class="docs-heading-anchor" href="#API">API</a><a id="API-1"></a><a class="docs-heading-anchor-permalink" href="#API" title="Permalink"></a></h1><p>Here is a list of available function calls. A detailed description can be found below. </p><ul><li><a href="#Knockoffs.Knockoff"><code>Knockoffs.Knockoff</code></a></li><li><a href="#Knockoffs.KnockoffFilter"><code>Knockoffs.KnockoffFilter</code></a></li><li><a href="#Knockoffs.MarkovChainTable"><code>Knockoffs.MarkovChainTable</code></a></li><li><a href="#Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T"><code>Knockoffs.MK_statistics</code></a></li><li><a href="#Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Array{Vector{T}, 1}}} where T"><code>Knockoffs.MK_statistics</code></a></li><li><a href="#Knockoffs.adj_constrained_hclust-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.adj_constrained_hclust</code></a></li><li><a href="#Knockoffs.approx_modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Symbol}"><code>Knockoffs.approx_modelX_gaussian_knockoffs</code></a></li><li><a href="#Knockoffs.block_diagonalize-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.block_diagonalize</code></a></li><li><a href="#Knockoffs.check_model_solution-Tuple{Any}"><code>Knockoffs.check_model_solution</code></a></li><li><a href="#Knockoffs.choose_group_reps-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}}} where T"><code>Knockoffs.choose_group_reps</code></a></li><li><a href="#Knockoffs.cond_indep_corr-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}}} where T"><code>Knockoffs.cond_indep_corr</code></a></li><li><a href="#Knockoffs.condition-Tuple{AbstractMatrix, AbstractVector, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.condition</code></a></li><li><a href="#Knockoffs.fit_lasso-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.fit_lasso</code></a></li><li><a href="#Knockoffs.fit_marginal-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.fit_marginal</code></a></li><li><a href="#Knockoffs.fixed_knockoffs-Union{Tuple{T}, Tuple{Matrix{T}, Symbol}} where T&lt;:AbstractFloat"><code>Knockoffs.fixed_knockoffs</code></a></li><li><a href="#Knockoffs.form_emission_prob_matrix-Tuple{Any, Any, AbstractVector, MarkovChainTable}"><code>Knockoffs.form_emission_prob_matrix</code></a></li><li><a href="#Knockoffs.forward_backward!"><code>Knockoffs.forward_backward!</code></a></li><li><a href="#Knockoffs.forward_backward_sampling!-Union{Tuple{T}, Tuple{Vector{Int64}, Vector, Array{T, 3}, Vector{T}, AbstractMatrix, MarkovChainTable, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix, AbstractVector}} where T"><code>Knockoffs.forward_backward_sampling!</code></a></li><li><a href="#Knockoffs.full_knockoffscreen-Tuple{SnpArrays.SnpArray}"><code>Knockoffs.full_knockoffscreen</code></a></li><li><a href="#Knockoffs.get_genotype_emission_probabilities-Tuple{AbstractMatrix, Number, Int64, Int64, Int64}"><code>Knockoffs.get_genotype_emission_probabilities</code></a></li><li><a href="#Knockoffs.get_genotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix, AbstractVector, MarkovChainTable}"><code>Knockoffs.get_genotype_transition_matrix</code></a></li><li><a href="#Knockoffs.get_haplotype_emission_probabilities-Tuple{AbstractMatrix, Int64, Number, Int64}"><code>Knockoffs.get_haplotype_emission_probabilities</code></a></li><li><a href="#Knockoffs.get_haplotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.get_haplotype_transition_matrix</code></a></li><li><a href="#Knockoffs.ghost_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.ghost_knockoffs</code></a></li><li><a href="#Knockoffs.group_block_objective-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Vector{Int64}, Number, Any}} where T"><code>Knockoffs.group_block_objective</code></a></li><li><a href="#Knockoffs.hc_partition_groups-Tuple{LinearAlgebra.Symmetric}"><code>Knockoffs.hc_partition_groups</code></a></li><li><a href="#Knockoffs.hmm_knockoff-Tuple{AbstractString}"><code>Knockoffs.hmm_knockoff</code></a></li><li><a href="#Knockoffs.hmm_knockoff-Tuple{SnpArrays.SnpData, AbstractVecOrMat, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.hmm_knockoff</code></a></li><li><a href="#Knockoffs.initialize_S"><code>Knockoffs.initialize_S</code></a></li><li><a href="#Knockoffs.inverse_mat_sqrt-Tuple{LinearAlgebra.Symmetric}"><code>Knockoffs.inverse_mat_sqrt</code></a></li><li><a href="#Knockoffs.ipad-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.ipad</code></a></li><li><a href="#Knockoffs.likelihood_ratio-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Number"><code>Knockoffs.likelihood_ratio</code></a></li><li><a href="#Knockoffs.lowrankdowndate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat"><code>Knockoffs.lowrankdowndate_turbo!</code></a></li><li><a href="#Knockoffs.lowrankupdate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat"><code>Knockoffs.lowrankupdate_turbo!</code></a></li><li><a href="#Knockoffs.markov_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{Int64}, Array{T, 3}, Vector{T}}} where T&lt;:AbstractFloat"><code>Knockoffs.markov_knockoffs</code></a></li><li><a href="#Knockoffs.mk_threshold-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}, Int64, Number}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any, Int64}} where T&lt;:AbstractFloat"><code>Knockoffs.mk_threshold</code></a></li><li><a href="#Knockoffs.modelX_gaussian_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T"><code>Knockoffs.modelX_gaussian_group_knockoffs</code></a></li><li><a href="#Knockoffs.modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Union{String, Symbol}}"><code>Knockoffs.modelX_gaussian_knockoffs</code></a></li><li><a href="#Knockoffs.modelX_gaussian_rep_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T"><code>Knockoffs.modelX_gaussian_rep_group_knockoffs</code></a></li><li><a href="#Knockoffs.normalize_col!-Tuple{AbstractVecOrMat}"><code>Knockoffs.normalize_col!</code></a></li><li><a href="#Knockoffs.prioritize_variants-Tuple{AbstractVector, AbstractVector}"><code>Knockoffs.prioritize_variants</code></a></li><li><a href="#Knockoffs.rapid-Tuple{AbstractString, AbstractString, AbstractString, Number, AbstractString, Int64, Int64, Int64}"><code>Knockoffs.rapid</code></a></li><li><a href="#Knockoffs.sample_mvn_efficient-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Int64}} where T"><code>Knockoffs.sample_mvn_efficient</code></a></li><li><a href="#Knockoffs.search_rank"><code>Knockoffs.search_rank</code></a></li><li><a href="#Knockoffs.shift_until_PSD!"><code>Knockoffs.shift_until_PSD!</code></a></li><li><a href="#Knockoffs.simulate_AR1-Tuple{Int64}"><code>Knockoffs.simulate_AR1</code></a></li><li><a href="#Knockoffs.simulate_ER-Tuple{Int64}"><code>Knockoffs.simulate_ER</code></a></li><li><a href="#Knockoffs.simulate_block_covariance-Union{Tuple{T}, Tuple{Vector{Int64}, T, T}} where T&lt;:AbstractFloat"><code>Knockoffs.simulate_block_covariance</code></a></li><li><a href="#Knockoffs.single_linkage_distance-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Vector{Int64}}} where T"><code>Knockoffs.single_linkage_distance</code></a></li><li><a href="#Knockoffs.single_state_dmc_knockoff!-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractVector{Int64}, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix{T}, Array{T, 3}, AbstractVector{T}, Int64}} where T"><code>Knockoffs.single_state_dmc_knockoff!</code></a></li><li><a href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_MVR</code></a></li><li><a href="#Knockoffs.solve_SDP-Tuple{AbstractMatrix}"><code>Knockoffs.solve_SDP</code></a></li><li><a href="#Knockoffs.solve_equi-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_equi</code></a></li><li><a href="#Knockoffs.solve_group_SDP_single_block-Tuple{AbstractMatrix, AbstractMatrix}"><code>Knockoffs.solve_group_SDP_single_block</code></a></li><li><a href="#Knockoffs.solve_group_SDP_subopt-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.solve_group_SDP_subopt</code></a></li><li><a href="#Knockoffs.solve_group_block_update-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_group_block_update</code></a></li><li><a href="#Knockoffs.solve_group_equi-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.solve_group_equi</code></a></li><li><a href="#Knockoffs.solve_group_max_entropy_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_max_entropy_hybrid</code></a></li><li><a href="#Knockoffs.solve_group_mvr_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_mvr_hybrid</code></a></li><li><a href="#Knockoffs.solve_group_sdp_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_sdp_hybrid</code></a></li><li><a href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_max_entropy</code></a></li><li><a href="#Knockoffs.solve_s-Tuple{LinearAlgebra.Symmetric, Union{String, Symbol}}"><code>Knockoffs.solve_s</code></a></li><li><a href="#Knockoffs.solve_s_graphical_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), AbstractVector{Int64}, AbstractVector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_s_graphical_group</code></a></li><li><a href="#Knockoffs.solve_s_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_s_group</code></a></li><li><a href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_sdp_ccd</code></a></li><li><a href="#Knockoffs.threshold-Union{Tuple{T}, Tuple{AbstractVector{T}, Number}, Tuple{AbstractVector{T}, Number, Any}, Tuple{AbstractVector{T}, Number, Any, Int64}} where T&lt;:AbstractFloat"><code>Knockoffs.threshold</code></a></li><li><a href="#Knockoffs.update_normalizing_constants!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64, Any}} where T&lt;:AbstractFloat"><code>Knockoffs.update_normalizing_constants!</code></a></li></ul><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Array{Vector{T}, 1}}} where T" href="#Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Array{Vector{T}, 1}}} where T"><code>Knockoffs.MK_statistics</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MK_statistics(T0::Vector, Tk::Vector{Vector}; filter_method)</code></pre><p>Computes the multiple knockoff statistics kappa, tau, and W. </p><p><strong>Inputs</strong></p><ul><li><code>T0</code>: p-vector of importance score for original variables</li><li><code>Tk</code>: Vector storing T1, ..., Tm, where Ti is importance scores for    the <code>i</code>th knockoff copy</li><li><code>filter_method</code>: Either <code>Statistics.median</code> (default) or max (original    function used in 2019 Gimenez and Zou)</li></ul><p><strong>output</strong></p><ul><li><code>κ</code>: Index of the most significant feature (<code>κ[i] = 0</code> if original feature most    important, otherwise <code>κ[i] = k</code> if the <code>k</code>th knockoff is most important)</li><li><code>τ</code>: <code>τ[i]</code> stores the most significant statistic among original and knockoff   variables minus <code>filter_method()</code> applied to the remaining statistics. </li><li><code>W</code>: coefficient difference statistic <code>W[i] = abs(T0[i]) - abs(Tk[i])</code>     </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/threshold.jl#L77-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T" href="#Knockoffs.MK_statistics-Union{Tuple{T}, Tuple{Vector{T}, Vector{T}}} where T"><code>Knockoffs.MK_statistics</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">MK_statistics(T0::Vector, Tk::Vector)</code></pre><p>Compute regular knockoff statistics tau and W. </p><p><strong>Inputs</strong></p><ul><li><code>T0</code>: p-vector of importance score for original variables</li><li><code>Tk</code>: p-vector of importance score for knockoff variables</li></ul><p><strong>output</strong></p><ul><li><code>W</code>: coefficient difference statistic <code>W[i] = abs(T0[i]) - abs(Tk[i])</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/threshold.jl#L122-L133">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.adj_constrained_hclust-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.adj_constrained_hclust-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.adj_constrained_hclust</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">adj_constrained_hclust(distmat::AbstractMatrix, h::Number)</code></pre><p>Performs (single-linkage) hierarchical clustering, forcing groups to be contiguous. After clustering, variables in different group is guaranteed to have distance  less than <code>h</code>. </p><p>Note: this is a custom (bottom-up) implementation because <code>Clustering.jl</code> does not  support adjacency constraints, see https://github.com/JuliaStats/Clustering.jl/issues/230</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1847-L1856">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.approx_modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Symbol}" href="#Knockoffs.approx_modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Symbol}"><code>Knockoffs.approx_modelX_gaussian_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">approx_modelX_gaussian_knockoffs(X, method; [m=1], [windowsize = 500], [covariance_approximator], kwargs...)
approx_modelX_gaussian_knockoffs(X, method, window_ranges; [m=1], [covariance_approximator], kwargs...)</code></pre><p>Generates Gaussian knockoffs by approximating the covariance as a block diagonal matrix.  Each block contains <code>windowsize</code> consecutive features. One could alternatively  specify the <code>window_ranges</code> argument to construct blocks of different sizes. </p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> numeric matrix or <code>SnpArray</code>. Each row is a sample, and each column is covariate.</li><li><code>method</code>: Can be one of the following<ul><li><code>:mvr</code> for minimum variance-based reconstructability knockoffs (alg 1 in ref 2)</li><li><code>:maxent</code> for maximum entropy knockoffs (alg 2 in ref 2)</li><li><code>:equi</code> for equi-distant knockoffs (eq 2.3 in ref 1), </li><li><code>:sdp</code> for SDP knockoffs (eq 2.4 in ref 1)</li><li><code>:sdp_fast</code> for SDP knockoffs via coordiate descent (alg 2.2 in ref 3)</li></ul></li><li><code>m</code>: Number of knockoff copies per variable to generate, defaults to 1. </li><li><code>windowsize</code>: Number of covariates to be included in a block. Each block consists of   adjacent variables. The last block could contain less than <code>windowsize</code> variables. </li><li><code>window_ranges</code>: Vector of ranges for each window. e.g. [1:97, 98:200, 201:500]</li><li><code>covariance_approximator</code>: A covariance estimator, defaults to <code>LinearShrinkage(DiagonalUnequalVariance(), :lw)</code>.   See CovarianceEstimation.jl for more options.</li><li><code>kwargs...</code>: Possible optional inputs to solvers specified in <code>method</code>, see    <a href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_MVR</code></a>, <a href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_max_entropy</code></a>, and <a href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_sdp_ccd</code></a></li></ul><p><strong>Multithreading (todo)</strong></p><p>To enable multiple threads, simply start Julia with &gt;1 threads and this routine will run with all available threads. </p><p><strong>Covariance Approximation:</strong></p><p>The covariance is approximated by a <code>LinearShrinkageEstimator</code> using  Ledoit-Wolf shrinkage with <code>DiagonalUnequalVariance</code> target,  which seems to perform well for <code>p&gt;n</code> cases. We do not simply use <code>cov(X)</code> since <code>isposdef(cov(X))</code> is typically false. For comparison of different estimators, see: https://mateuszbaran.github.io/CovarianceEstimation.jl/dev/man/msecomp/#msecomp</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/approx.jl#L1-L36">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.block_diagonalize-Tuple{AbstractMatrix, Vector{Int64}}" href="#Knockoffs.block_diagonalize-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.block_diagonalize</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">block_diagonalize(Σ, groups)</code></pre><p>Internal function to block-diagonalize the covariance <code>Σ</code> according to groups. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L456-L460">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.check_model_solution-Tuple{Any}" href="#Knockoffs.check_model_solution-Tuple{Any}"><code>Knockoffs.check_model_solution</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">check_model_solution(model; verbose=false)</code></pre><p>After solving a JuMP model, checks if the solution is accurate. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L627-L631">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.choose_group_reps-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}}} where T" href="#Knockoffs.choose_group_reps-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}}} where T"><code>Knockoffs.choose_group_reps</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">choose_group_reps(Σ::Symmetric, groups::AbstractVector; [threshold=0.5], [prioritize_idx], [Σinv])</code></pre><p>Chooses group representatives. Returns indices of <code>Σ</code> that are representatives. If R is the set of selected variables within a group and O is the set of variables outside the group, then we keep adding variables to R until the proportion of variance explained by R divided by the proportion of variance explained by R and O exceeds <code>threshold</code>. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Correlation matrix wrapped in the <code>Symmetric</code> argument.</li><li><code>groups</code>: Vector of group membership. </li></ul><p><strong>Optional inputs</strong></p><ul><li><code>threshold</code>: Value between 0 and 1 that controls the number of    representatives per group. Larger means more representatives (default 0.5)</li><li><code>prioritize_idx</code>: Variable indices that should receive priority to be chosen   as representatives, defaults to <code>nothing</code></li><li><code>Σinv</code>: Precomputed <code>inv(Σ)</code> (it will be computed if not supplied)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1909-L1928">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.cond_indep_corr-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}}} where T" href="#Knockoffs.cond_indep_corr-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}}} where T"><code>Knockoffs.cond_indep_corr</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Returns <code>Σnew</code> as a covariance matrix that strictly satisfies the conditional independence assumption. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L202-L205">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.condition-Tuple{AbstractMatrix, AbstractVector, AbstractMatrix, AbstractMatrix}" href="#Knockoffs.condition-Tuple{AbstractMatrix, AbstractVector, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.condition</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">condition(x::AbstractVector, μ::AbstractVector, Σ::AbstractMatrix, S::AbstractMatrix, [m::Number=1])</code></pre><p>Samples a knockoff x̃ from Gaussian x using conditional distribution formulas:</p><p>If (x, x̃) ~ N((μ, μ), G) where G = [Σ  Σ - S; Σ - S  Σ], then we sample x̃ from  x̃|x = N(μ+(Σ-S)<em>inv(Σ)</em>(x-μ) , 2S-S<em>inv(Σ)</em>S). </p><p>If we sample <code>m</code> knockoffs, we use the algorithm in  &quot;Improving the Stability of the Knockoff Procedure: Multiple Simultaneous Knockoffs  and Entropy Maximization&quot; by Gimenez and Zou.</p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> numeric matrix, each row is a sample, and each column is covariate.</li><li><code>μ</code>: A <code>p × 1</code> vector of column mean of <code>X</code></li><li><code>Σ</code>: A <code>p × p</code> covariance matrix of <code>X</code></li><li><code>S</code>: A <code>p × p</code> matrix solved to satisfy <code>S ⪰ 0</code> and <code>(m+1)/m*Σ - S ⪰ 0</code></li><li><code>m</code>: Number of (simultaneous) knockoffs per variable to generate, default <code>m=1</code></li></ul><p><strong>Output</strong></p><ul><li><code>X̃</code>: A <code>n × pm</code> numeric matrix. The first <code>p</code> columns store the first knockoff copy,   and the next <code>p</code> columns store the second knockoff...etc</li></ul><p><strong>Todo</strong></p><ul><li>When s is the zero vector, X̃ should be identical to X but it isn&#39;t</li><li>Consider changing sampling code to using Distribution&#39;s MvNormal</li><li>For multiple knockoffs, can we avoid storing a pm × pm matrix in memory?</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/modelX.jl#L68-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.fit_lasso-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T" href="#Knockoffs.fit_lasso-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.fit_lasso</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit_lasso(y, X, [method], [d], [m], [fdrs], [groups], [filter_method], 
    [debias], [kwargs...])
fit_lasso(y, X, μ, Σ, [method], [d], [m], [fdrs], [groups], [filter_method], 
    [debias], [kwargs...])</code></pre><p>Generates model-X knockoffs with <code>method</code>, runs Lasso, then applies the  knockoff-filter. If <code>μ</code> and <code>Σ</code> are not provided, they will be estimated from data. </p><p><strong>Inputs</strong></p><ul><li><code>y</code>: A <code>n × 1</code> response vector</li><li><code>X</code>: A <code>n × p</code> numeric matrix, each row is a sample, and each column is covariate.</li><li><code>method</code>: Method for knockoff generation (defaults to <code>:maxent</code>)</li><li><code>μ</code>: A <code>p × 1</code> vector of column mean of <code>X</code>. If not provided, defaults to column mean.</li><li><code>Σ</code>: A <code>p × p</code> covariance matrix of <code>X</code>. If not provided, it will be estimated    based on a shrinked empirical covariance matrix, see <a href="#Knockoffs.modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Union{String, Symbol}}"><code>modelX_gaussian_knockoffs</code></a></li><li><code>d</code>: Distribution of response. Defaults <code>Normal()</code>, for binary response   (logistic regression) use <code>Binomial()</code>.</li><li><code>m</code>: Number of simultaneous knockoffs to generate, defaults to <code>m=1</code></li><li><code>fdrs</code>: Target FDRs, defaults to <code>[0.01, 0.05, 0.1, 0.25, 0.5]</code></li><li><code>groups</code>: Vector of group membership. If not supplied, we generate regular knockoffs.   If supplied, we run group knockoffs.</li><li><code>filter_method</code>: Choices are <code>:knockoff</code> or <code>:knockoff_plus</code> (default) </li><li><code>debias</code>: Defines how the selected coefficients are debiased. Specify <code>:ls</code>    for least squares or <code>:lasso</code> for Lasso (only running on the    support). To not debias, specify <code>debias=nothing</code> (default).</li><li><code>kwargs</code>: Additional arguments to input into <code>glmnetcv</code> and <code>glmnet</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/fit_lasso.jl#L1-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.fit_marginal-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T" href="#Knockoffs.fit_marginal-Union{Tuple{T}, Tuple{AbstractVecOrMat{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.fit_marginal</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fit_marginal(y, X, method=:maxent, ...)
fit_marginal(y, X, μ, Σ, method=:maxent, ...)</code></pre><p>Generates model-X knockoffs with <code>method</code> and computes feature importance statistics based on squared marginal Z score: abs2(x[:, i]^t*y) / n. If <code>μ</code> and <code>Σ</code> are not provided, they will be estimated from data. </p><p><strong>Inputs</strong></p><ul><li><code>y</code>: A <code>n × 1</code> response vector</li><li><code>X</code>: A <code>n × p</code> numeric matrix, each row is a sample, and each column is covariate.</li><li><code>method</code>: Method for knockoff generation (defaults to <code>:maxent</code>)</li><li><code>μ</code>: A <code>p × 1</code> vector of column mean of <code>X</code>. If not provided, defaults to column mean.</li><li><code>Σ</code>: A <code>p × p</code> covariance matrix of <code>X</code>. If not provided, it will be estimated    based on a shrinked empirical covariance matrix, see <a href="#Knockoffs.modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Union{String, Symbol}}"><code>modelX_gaussian_knockoffs</code></a></li><li><code>d</code>: Distribution of response. Defaults <code>Normal()</code>, for binary response   (logistic regression) use <code>Binomial()</code>.</li><li><code>m</code>: Number of simultaneous knockoffs to generate, defaults to <code>m=1</code></li><li><code>fdrs</code>: Target FDRs, defaults to <code>[0.01, 0.05, 0.1, 0.25, 0.5]</code></li><li><code>groups</code>: Vector of group membership. If not supplied, we generate regular knockoffs.   If supplied, we run group knockoffs.</li><li><code>filter_method</code>: Choices are <code>:knockoff</code> or <code>:knockoff_plus</code> (default) </li><li><code>debias</code>: Defines how the selected coefficients are debiased. Specify <code>:ls</code>    for least squares or <code>:lasso</code> for Lasso (only running on the    support). To not debias, specify <code>debias=nothing</code> (default).</li><li><code>kwargs</code>: Additional arguments to input into <code>glmnetcv</code> and <code>glmnet</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/fit_lasso.jl#L160-L186">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.fixed_knockoffs-Union{Tuple{T}, Tuple{Matrix{T}, Symbol}} where T&lt;:AbstractFloat" href="#Knockoffs.fixed_knockoffs-Union{Tuple{T}, Tuple{Matrix{T}, Symbol}} where T&lt;:AbstractFloat"><code>Knockoffs.fixed_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">fixed_knockoffs(X::Matrix{T}; [method], [kwargs...])</code></pre><p>Creates fixed-X knockoffs. Internally, <code>X</code> will be automatically normalized before computing its knockoff. </p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A column-normalized <code>n × p</code> numeric matrix, each row is a sample, and   each column is covariate. We will internally normalized <code>X</code> if it is not. </li><li><code>method</code>: Can be one of the following<ul><li><code>:mvr</code>: Minimum variance-based reconstructability knockoffs (alg 1 in ref 2)</li><li><code>:maxent</code>: Maximum entropy knockoffs (alg 2 in ref 2)</li><li><code>:equi</code>: Equi-distant knockoffs (eq 2.3 in ref 1), </li><li><code>:sdp</code>: SDP knockoffs (eq 2.4 in ref 1)</li><li><code>:sdp_fast</code>: SDP knockoffs via coordiate descent (alg 2.2 in ref 3)</li></ul></li><li><code>kwargs...</code>: Possible optional inputs to <code>method</code>, see <a href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_MVR</code></a>,    <a href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_max_entropy</code></a>, and <a href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_sdp_ccd</code></a></li></ul><p><strong>Output</strong></p><ul><li><code>GaussianKnockoff</code>: A struct containing the original (column-normalized) <code>X</code>   and its knockoff <code>X̃</code>, in addition to other variables (e.g. <code>s</code>)</li></ul><p><strong>Reference</strong></p><ol><li>&quot;Controlling the false discovery rate via Knockoffs&quot; by Barber and Candes (2015).</li><li>&quot;Powerful knockoffs via minimizing reconstructability&quot; by Spector, Asher, and Lucas Janson (2020)</li><li>&quot;FANOK: Knockoffs in Linear Time&quot; by Askari et al. (2020).</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/fixed.jl#L1-L27">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.form_emission_prob_matrix-Tuple{Any, Any, AbstractVector, MarkovChainTable}" href="#Knockoffs.form_emission_prob_matrix-Tuple{Any, Any, AbstractVector, MarkovChainTable}"><code>Knockoffs.form_emission_prob_matrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">form_emission_prob_matrix(a, θ, xi::AbstractVector)</code></pre><p><strong>Inputs</strong></p><ul><li><code>a</code>: <code>p × K</code> matrix with values estimated from fastPHASE (i.e. they called it the α parameter)</li><li><code>θ</code>: <code>p × K</code> matrix with values estimated from fastPHASE</li><li><code>xi</code>: Length <code>p</code> vector with sample <code>i</code>&#39;s genotypes (entries 0, 1 or 2) </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L142-L149">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.forward_backward!" href="#Knockoffs.forward_backward!"><code>Knockoffs.forward_backward!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">forward_backward!(x, L, y, storage=zeros(length(x)))</code></pre><p>Non-allocating solver for finding <code>x</code> to the solution of LL&#39;x = y where L is a cholesky factor. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L177-L181">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.forward_backward_sampling!-Union{Tuple{T}, Tuple{Vector{Int64}, Vector, Array{T, 3}, Vector{T}, AbstractMatrix, MarkovChainTable, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix, AbstractVector}} where T" href="#Knockoffs.forward_backward_sampling!-Union{Tuple{T}, Tuple{Vector{Int64}, Vector, Array{T, 3}, Vector{T}, AbstractMatrix, MarkovChainTable, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix, AbstractVector}} where T"><code>Knockoffs.forward_backward_sampling!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">forward_backward_sampling!(Z, X, Q, q, θ, ...)</code></pre><p>Samples Z, the hidden states of a HMM, from observed sequence of unphased genotypes X.</p><p><strong>Inputs</strong></p><p><code>Z</code>: Length <code>p</code> vector of integers. This will store the sampled Markov states <code>X</code>: Length <code>p</code> vector of genotypes (0, 1, or 2) <code>Q</code>: <code>K × K × p</code> array. <code>Q[:, :, j]</code> is a <code>K × K</code> matrix of transition     probabilities for <code>j</code>th state, i.e. Q[l, k, j] = P(X<em>{j} = k | X</em>{j - 1} = l).     The first transition matrix is not used.  <code>q</code>: Length <code>K</code> vector of initial probabilities <code>θ</code>: The θ parameter estimated from fastPHASE</p><p><strong>Preallocated storage variables</strong></p><p><code>table</code>: a <code>MarkovChainTable</code> that maps markov chain states to haplotype      pairs (ka, kb) <code>d</code>: Sampling distribution, probabilities in d.p are mutated <code>α̂</code>: <code>p × K</code> scaled forward probability matrix, where      <code>α̂[j, k] = P(x_1,...,x_k, z_k) / P(x_1,...,x_k)</code> <code>c</code>: normalizing constants, <code>c[k] = p(x_k | x_1,...,x_{k-1})</code></p><p><strong>Reference</strong></p><p>Algorithm 3 of &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia et al</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L160-L184">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.full_knockoffscreen-Tuple{SnpArrays.SnpArray}" href="#Knockoffs.full_knockoffscreen-Tuple{SnpArrays.SnpArray}"><code>Knockoffs.full_knockoffscreen</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">full_knockoffscreen(x::SnpArray; windowsize::Int=100)</code></pre><p>Generates knockoffs <code>X̃ⱼ</code> by on regressing <code>Xⱼ</code> on SNPs knockoffs within a sliding window of width <code>windowsize</code>. </p><p><strong>Inputs</strong></p><ul><li><code>x</code>: A <code>SnpArray</code> or <code>String</code> for the path of the PLINK <code>.bed</code> file</li><li><code>windowsize</code>: <code>Int</code> specifying window width. Defaults to 100</li></ul><p><strong>Outputs</strong></p><ul><li><code>X̃</code>: A <code>n × p</code> dense matrix of <code>Float64</code>, each row is a sample.</li></ul><p><strong>References</strong></p><ul><li>He, Zihuai, Linxi Liu, Chen Wang, Yann Le Guen, Justin Lee, Stephanie Gogarten, Fred Lu et al. &quot;Identification of putative causal loci in whole-genome sequencing data via knockoff statistics.&quot; Nature communications 12, no. 1 (2021): 1-18.</li><li>He, Zihuai, Yann Le Guen, Linxi Liu, Justin Lee, Shiyang Ma, Andrew C. Yang, Xiaoxia Liu et al. &quot;Genome-wide analysis of common and rare variants via multiple knockoffs at biobank scale, with an application to Alzheimer disease genetics.&quot; The American Journal of Human Genetics 108, no. 12 (2021): 2336-2353.</li></ul><p><strong>TODO</strong></p><ul><li>Use <code>ElasticArrays.jl</code> to avoid reallocating design matrix in each loop</li><li>Write iterator interface to avoid allocating and storing all knockoffs at once</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/knockoffscreen.jl#L31-L50">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.get_genotype_emission_probabilities-Tuple{AbstractMatrix, Number, Int64, Int64, Int64}" href="#Knockoffs.get_genotype_emission_probabilities-Tuple{AbstractMatrix, Number, Int64, Int64, Int64}"><code>Knockoffs.get_genotype_emission_probabilities</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_genotype_emission_probabilities(θ::AbstractMatrix, xj::Number, ka::Int, kb::Int, j::Int)</code></pre><p>Computes P(xj | k={ka,kb}, θ): emission probabilities for genotypes. This is eq 10 of  &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia et al.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L118-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.get_genotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix, AbstractVector, MarkovChainTable}" href="#Knockoffs.get_genotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix, AbstractVector, MarkovChainTable}"><code>Knockoffs.get_genotype_transition_matrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_genotype_transition_matrix(r, θ, α, q, table)</code></pre><p>Compute transition matrices for the hidden Markov chains in unphased genotypes.  This is equation 9 of &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia et al.</p><p><strong>Inputs</strong></p><p><code>r</code>: Length <code>p</code> vector, the &quot;recombination rates&quot; <code>θ</code>: Size <code>p × K</code> matrix, <code>θ[j, k]</code> is probability that the allele is 1 for SNP <code>p</code> at <code>k</code>th haplotype motif <code>α</code>: Size <code>p × K</code> matrix, probabilities that haplotype motifs succeed each other. Rows should sum to 1.  <code>q</code>: Length <code>K</code> vector of initial probabilities <code>table</code>: a <code>MarkovChainTable</code> that maps markov chain states k = 1, ..., K+(K+1)/2     to haplotype pairs (ka, kb). </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L36-L49">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.get_haplotype_emission_probabilities-Tuple{AbstractMatrix, Int64, Number, Int64}" href="#Knockoffs.get_haplotype_emission_probabilities-Tuple{AbstractMatrix, Int64, Number, Int64}"><code>Knockoffs.get_haplotype_emission_probabilities</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_haplotype_emission_probabilities(θ::AbstractMatrix, j::Int, hj::Number, zj::Int)</code></pre><p>Computes emission probabilities for unphased HMM. This is the equation above eq8 of  &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia et al.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L102-L107">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.get_haplotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix}" href="#Knockoffs.get_haplotype_transition_matrix-Tuple{AbstractVecOrMat, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.get_haplotype_transition_matrix</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">get_haplotype_transition_matrix(r, θ, α)</code></pre><p>Compute transition matrices for the hidden Markov chains in haplotypes.  This is 2 equations above eq8 in &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia et al.</p><p><strong>Inputs</strong></p><p><code>r</code>: Length <code>p</code> vector, the &quot;recombination rates&quot; <code>θ</code>: Size <code>p × K</code> matrix, <code>θ[j, k]</code> is probability that the allele is 1 for SNP <code>p</code> at <code>k</code>th haplotype motif <code>α</code>: Size <code>p × K</code> matrix, probabilities that haplotype motifs succeed each other. Rows should sum to 1. </p><p><strong>Output</strong></p><p><code>Q</code>: A <code>p</code>-dimensional vector of <code>K × K</code> matrices. <code>Q[:, :, j]</code> is the <code>j</code>th transition matrix. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L2-L15">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.ghost_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T" href="#Knockoffs.ghost_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{T}, AbstractMatrix{T}, AbstractMatrix{T}}} where T"><code>Knockoffs.ghost_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ghost_knockoffs(Zscores, D, Σinv; [m=1])</code></pre><p>Generate Ghost knockoffs given a list of z-scores (GWAS summary statistic). </p><p><strong>Inputs</strong></p><ul><li><code>Zscores</code>: List of z-score statistics</li><li><code>D</code>: Matrix obtained from solving the knockoff problem satisfying    <code>(m+1)/m*Σ - D ⪰ 0</code></li><li><code>Σinv</code>: Inverse of the covariance matrix</li></ul><p><strong>optional inputs</strong></p><ul><li><code>m</code>: Number of knockoffs</li></ul><p><strong>Reference</strong></p><p>He, Z., Liu, L., Belloy, M. E., Le Guen, Y., Sossin, A., Liu, X., ... &amp; Ionita-Laza, I. (2021).  Summary statistics knockoff inference empowers identification of putative causal variants in  genome-wide association studies. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/ghost.jl#L6-L24">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.group_block_objective-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Vector{Int64}, Number, Any}} where T" href="#Knockoffs.group_block_objective-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Vector{Int64}, Number, Any}} where T"><code>Knockoffs.group_block_objective</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">group_block_objective(Σ, S, groups, m, method)</code></pre><p>Evaluate the objective for SDP/MVR/ME. This is not an efficient function, so it should only be called at the start of each algorithm. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Covariance or correlation matrix for original data</li><li><code>S</code>: Optimization variable (group-block-diagonal)</li><li><code>groups</code>: Vector of group membership. Variable <code>i</code> belongs to group <code>groups[i]</code></li><li><code>m</code>: Number of knockoffs to generate for each variable</li><li><code>method</code>: The optimization method for group knockoffs</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1-L13">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.hc_partition_groups-Tuple{LinearAlgebra.Symmetric}" href="#Knockoffs.hc_partition_groups-Tuple{LinearAlgebra.Symmetric}"><code>Knockoffs.hc_partition_groups</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hc_partition_groups(X::AbstractMatrix; [cutoff], [min_clusters], [force_contiguous])
hc_partition_groups(Σ::Symmetric; [cutoff], [min_clusters], [force_contiguous])</code></pre><p>Computes a group partition based on individual level data <code>X</code> or correlation  matrix <code>Σ</code> using hierarchical clustering with specified linkage. </p><p><strong>Inputs</strong></p><ul><li><code>X</code>: <code>n × p</code> data matrix. Each row is a sample</li><li><code>Σ</code>: <code>p × p</code> correlation matrix. Must be wrapped in the <code>Symmetric</code> argument,   otherwise we will treat it as individual level data</li><li><code>cutoff</code>: Height value for which the clustering result is cut, between 0 and 1   (default 0.5). This ensures that no variables between 2 groups have correlation   greater than <code>cutoff</code>. 1 recovers ungrouped structure, 0 corresponds to    everything in a single group. </li><li><code>min_clusters</code>: The desired number of clusters. </li><li><code>linkage</code>: <em>cluster linkage</em> function to use (when <code>force_contiguous=true</code>,    <code>linkage</code> must be <code>:single</code>). <code>linkage</code> defines how the    distances between the data points are aggregated into the distances between    the clusters. Naturally, it affects what clusters are merged on each    iteration. The valid choices are:<ul><li><code>:single</code> (default): use the minimum distance between any of the cluster members</li><li><code>:average</code>: use the mean distance between any of the cluster members</li><li><code>:complete</code>: use the maximum distance between any of the members</li><li><code>:ward</code>: the distance is the increase of the average squared distance of a   point to its cluster centroid after merging the two clusters</li><li><code>:ward_presquared</code>: same as <code>:ward</code>, but assumes that the distances in d    are already squared.</li></ul></li><li><code>rep_method</code>: Method for selecting representatives for each group. Options are   <code>:id</code> (tends to select roughly independent variables) or <code>:rss</code> (tends to   select more correlated variables)</li></ul><p>If <code>force_contiguous = false</code> and both <code>min_clusters</code> and <code>cutoff</code> are specified,  it is guaranteed that the number of clusters is not less than <code>min_clusters</code> and their height is not above <code>cutoff</code>. If <code>force_contiguous = true</code>, <code>min_clusters</code> keyword is ignored. </p><p><strong>Outputs</strong></p><ul><li><code>groups</code>: Length <code>p</code> vector of group membership for each variable</li><li><code>group_reps</code>: Columns of X selected as representatives. Each group have at    most <code>nrep</code> representatives. These are typically used to construct smaller   group knockoff for extremely large groups</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1770-L1812">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.hmm_knockoff-Tuple{AbstractString}" href="#Knockoffs.hmm_knockoff-Tuple{AbstractString}"><code>Knockoffs.hmm_knockoff</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hmm_knockoff(plinkname; [datadir], [plink_outfile], [fastphase_outfile], [outdir], [verbose], args...)</code></pre><p>Generates HMM knockoffs from binary PLINK formatted files. This is done by first running fastPHASE, then running Algorithm 2 of &quot;Gene hunting with hidden Markov model knockoffs&quot; by Sesia, Sabatti, and Candes</p><p><strong>Input</strong></p><ul><li><code>plinkname</code>: Binary PLINK file names without the <code>.bed/.bim/.fam</code> suffix. </li></ul><p><strong>Optional arguments</strong></p><ul><li><code>datadir</code>: Full path to the PLINK and fastPHASE files (default = current directory)</li><li><code>plink_outfile</code>: Output PLINK format name</li><li><code>fastphase_outfile</code>: The output file name from fastPHASE&#39;s alpha, theta, r files</li><li><code>args...</code>: Any parameter that accepted in <code>fastPHASE.fastphase_estim_param()</code></li></ul><p><strong>Output</strong></p><ul><li><code>plink_outfile.bed</code>: <code>n × p</code> knockoff genotypes</li><li><code>plink_outfile.bim</code>: SNP mapping file. Knockoff have SNP names ending in &quot;.k&quot;</li><li><code>plink_outfile.fam</code>: Sample mapping file, this is a copy of the original <code>plinkname.fam</code> file</li><li><code>fastphase_outfile_rhat.txt</code>: averaged r hat file from fastPHASE</li><li><code>fastphase_outfile_alphahat.txt</code>: averaged alpha hat file from fastPHASE</li><li><code>fastphase_outfile_thetahat.txt</code>: averaged theta hat file from fastPHASE</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L255-L278">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.hmm_knockoff-Tuple{SnpArrays.SnpData, AbstractVecOrMat, AbstractMatrix, AbstractMatrix}" href="#Knockoffs.hmm_knockoff-Tuple{SnpArrays.SnpData, AbstractVecOrMat, AbstractMatrix, AbstractMatrix}"><code>Knockoffs.hmm_knockoff</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">hmm_knockoff(snpdata::SnpData, r::AbstractVecOrMat, θ::AbstractMatrix, α::AbstractMatrix)</code></pre><p>Generates knockoff of <code>snpdata</code> with loaded r, θ, α</p><p><strong>Input</strong></p><ul><li><code>SnpData</code>: A <code>SnpData</code> object from SnpArrays</li><li><code>r</code>: The r vector estimated by fastPHASE</li><li><code>θ</code>: The θ matrix estimated by fastPHASE</li><li><code>α</code>: The α matrix estimated by fastPHASE</li></ul><p><strong>Optional Inputs</strong></p><ul><li><code>outdir</code>: Output directory for generated knockoffs</li><li><code>plink_outfile</code>: Output file name for knockoff genotypes</li><li><code>estimate_δ</code>: If true, will estimate pseudo-FDR by computing a δ value    for each SNP via likelihood ratio bound</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L310-L326">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.initialize_S" href="#Knockoffs.initialize_S"><code>Knockoffs.initialize_S</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">initialize_S(Σ, groups, m, method, verbose)</code></pre><p>Internal function to help initialize <code>S</code> to a good starting value, returns the final <code>S</code> matrix as well as the cholesky factorizations <code>L</code> and <code>C</code> where</p><ul><li>L.L<em>L.U = cholesky((m+1)/m</em>Σ - S)</li><li>C.L*C.U = cholesky(S)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L424-L431">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.inverse_mat_sqrt-Tuple{LinearAlgebra.Symmetric}" href="#Knockoffs.inverse_mat_sqrt-Tuple{LinearAlgebra.Symmetric}"><code>Knockoffs.inverse_mat_sqrt</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Computes A^{-1/2} via eigen-decomposition</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L445-L447">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.ipad-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.ipad-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.ipad</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">ipad(X::Matrix; [r_method], [m])</code></pre><p>Generates knockoffs based on intertwined probabilitistic factors decoupling (IPAD). This assumes that <code>X</code> can be factored as <code>X = FΛ&#39; + E</code> where <code>F</code> is a <code>n × r</code> random matrix of latent factors, <code>Λ</code> are factor loadings, and <code>E</code> are residual errors. When this assumption is met, FDR can be controlled with no power loss when applying the knockoff procedure. Internally, we need to compute an eigenfactorization for a <code>n × n</code> matrix. This is often faster than standard model-X knockoffs which requires solving <code>p</code>-dimensional convex optimization problem.</p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> numeric matrix, each row is a sample, and each column is covariate.</li><li><code>r_method</code>: Method used for estimating <code>r</code>, the number of latent factors.    Choices include <code>:er</code> (default), <code>:gr</code>, or <code>:ve</code></li><li><code>m</code>: Number of (simultaneous) knockoffs per variable to generate, default <code>m=1</code></li></ul><p><strong>References</strong></p><ul><li>Fan, Y., Lv, J., Sharifvaghefi, M. and Uematsu, Y., 2020. IPAD: stable interpretable forecasting with knockoffs inference. Journal of the American Statistical Association, 115(532), pp.1822-1834.</li><li>Bai, J., 2003. Inferential theory for factor models of large dimensions. Econometrica, 71(1), pp.135-171.</li><li>Ahn, S.C. and Horenstein, A.R., 2013. Eigenvalue ratio test for the number of factors. Econometrica, 81(3), pp.1203-1227.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/ipad.jl#L1-L23">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.likelihood_ratio-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Number" href="#Knockoffs.likelihood_ratio-Union{Tuple{T}, Tuple{T, T, T}} where T&lt;:Number"><code>Knockoffs.likelihood_ratio</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">likelihood_ratio(θa, θb, ρ; α=0.1, n = 1000, threshold = true)</code></pre><p>Estimates the likelihood ratio bound log(P(x)Q(x̃) / Q(x)P(x̃)) for each a single HMM state (fixed i and j)</p><ul><li>θa: State 1 of genotype markov state</li><li>θb: State 2 of genotype markov state</li><li>ρ is maf of SNP</li><li>α is % SNPs decorrelated (defaults 10%)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm.jl#L436-L446">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.lowrankdowndate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat" href="#Knockoffs.lowrankdowndate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat"><code>Knockoffs.lowrankdowndate_turbo!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">lowrankdowndate_turbo!(C::Cholesky, v::AbstractVector)</code></pre><p>Vectorized version of lowrankdowndate!, source https://github.com/JuliaLang/julia/blob/742b9abb4dd4621b667ec5bb3434b8b3602f96fd/stdlib/LinearAlgebra/src/cholesky.jl#L753 Takes advantage of the fact that <code>v</code> is 0 everywhere except at 1 position</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L565-L570">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.lowrankupdate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat" href="#Knockoffs.lowrankupdate_turbo!-Union{Tuple{T}, Tuple{LinearAlgebra.Cholesky{T}, AbstractVector}} where T&lt;:AbstractFloat"><code>Knockoffs.lowrankupdate_turbo!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">lowrankupdate_turbo!(C::Cholesky, v::AbstractVector)</code></pre><p>Vectorized version of lowrankupdate!, source https://github.com/JuliaLang/julia/blob/742b9abb4dd4621b667ec5bb3434b8b3602f96fd/stdlib/LinearAlgebra/src/cholesky.jl#L707 Takes advantage of the fact that <code>v</code> is 0 everywhere except at 1 position</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L510-L515">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.markov_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{Int64}, Array{T, 3}, Vector{T}}} where T&lt;:AbstractFloat" href="#Knockoffs.markov_knockoffs-Union{Tuple{T}, Tuple{AbstractVector{Int64}, Array{T, 3}, Vector{T}}} where T&lt;:AbstractFloat"><code>Knockoffs.markov_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">markov_knockoffs(Z::Vector{Int}, Q::Array{T, 3}, q::Vector{T})</code></pre><p>Generates knockoff of variables distributed as a discrete Markov Chain with <code>K</code> states.</p><p><strong>Inputs</strong></p><ul><li><code>Z</code>: Length <code>p</code> vector of <code>Int</code> where <code>Z[i]</code> is the <code>i</code>th state</li><li><code>Q</code>: <code>K × K × p</code> array. <code>Q[:, :, j]</code> is a <code>K × K</code> matrix of transition   probabilities for <code>j</code>th state, i.e. Q[l, k, j] = P(X<em>{j} = k | X</em>{j - 1} = l)   The first transition matrix is not used. </li><li><code>q</code>: <code>K × 1</code> vector of initial probabilities</li></ul><p><strong>Reference</strong></p><p>Equations 4-5 of &quot;Gene hunting with hidden Markov model knockoffs&quot; by  Sesia, Sabatti, and Candes</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/dmc.jl#L1-L17">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.mk_threshold-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}, Int64, Number}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any, Int64}} where T&lt;:AbstractFloat" href="#Knockoffs.mk_threshold-Union{Tuple{T}, Tuple{Vector{T}, Vector{Int64}, Int64, Number}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any}, Tuple{Vector{T}, Vector{Int64}, Int64, Number, Any, Int64}} where T&lt;:AbstractFloat"><code>Knockoffs.mk_threshold</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">mk_threshold(τ::Vector{T}, κ::Vector{Int}, m::Int, q::Number)</code></pre><p>Chooses the multiple knockoff threshold <code>τ̂ &gt; 0</code> by setting τ̂ = min{ t &gt; 0 : (1/m + 1/m * {#j: κ[j] ≥ 1 and W[j] ≥ t}) / {#j: κ[j] == 0 and W[j] ≥ τ̂} ≤ q }.</p><p><strong>Inputs</strong></p><ul><li><code>τ</code>: τ[i] stores the feature importance score for the ith feature, i.e. the value   T0 - median(T1,...,Tm). Note in Gimenez and Zou, the max function is used    instead of median</li><li><code>κ</code>: κ[i] stores which of m knockoffs has largest importance score. When original    variable has largest score, κ[i] == 0.</li><li><code>m</code>: Number of knockoffs per variable generated</li><li><code>q</code>: target FDR (between 0 and 1)</li><li><code>rej_bounds</code>: Number of values of top τ to consider (default = 10000)</li></ul><p><strong>Reference:</strong></p><ul><li>Equations 8 and 9 in supplement of &quot;Identification of putative causal loci in    wholegenome sequencing data via knockoff statistics&quot; by He et al. </li><li>Algorithm 1 of &quot;Improving the Stability of the Knockoff Procedure: Multiple    Simultaneous Knockoffs and Entropy Maximization&quot; by Gimenez and Zou.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/threshold.jl#L33-L54">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.modelX_gaussian_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T" href="#Knockoffs.modelX_gaussian_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T"><code>Knockoffs.modelX_gaussian_group_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">modelX_gaussian_group_knockoffs(X, method, groups, μ, Σ; [m], [covariance_approximator], [kwargs])
modelX_gaussian_group_knockoffs(X, method, groups; [m], [covariance_approximator], [kwargs])</code></pre><p>Constructs Gaussian model-X group knockoffs. If the covariance <code>Σ</code> and mean <code>μ</code>  are not specified, they will be estimated from data, i.e. we will make second-order group knockoffs. To incorporate group structure, the (true or estimated) covariance  matrix is block-diagonalized according to <code>groups</code> membership to solve a relaxed  optimization problem. See reference paper and Knockoffs.jl docs for more details. </p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> design matrix. Each row is a sample, each column is a feature.</li><li><code>method</code>: Method for constructing knockoffs. Options include<ul><li><code>:maxent</code>: (recommended) for fully general maximum entropy group knockoffs</li><li><code>:mvr</code>: for fully general minimum variance-based reconstructability (MVR) group    knockoffs</li><li><code>:equi</code>: for equi-correlated knockoffs. This is the methodology proposed in   <code>Dai R, Barber R. The knockoff filter for FDR control in group-sparse and multitask regression.    International conference on machine learning 2016 Jun 11 (pp. 1851-1859). PMLR.</code></li><li><code>:sdp</code>: Fully general SDP group knockoffs based on coodinate descent</li><li><code>:sdp_block</code>: Fully general SDP group knockoffs where each block is solved exactly    using an interior point solver. </li><li><code>:sdp_subopt</code>: Chooses each block <code>S_{i} = γ_i * Σ_{ii}</code>. This slightly    generalizes the equi-correlated group knockoff idea proposed in Dai and Barber 2016.</li></ul></li><li><code>groups</code>: Vector of group membership</li><li><code>μ</code>: A length <code>p</code> vector storing the true column means of <code>X</code></li><li><code>Σ</code>: A <code>p × p</code> covariance matrix for columns of <code>X</code></li><li><code>m</code>: Number of knockoffs per variable, defaults to 1. </li><li><code>covariance_approximator</code>: A covariance estimator, defaults to    <code>LinearShrinkage(DiagonalUnequalVariance(), :lw)</code>. See CovarianceEstimation.jl    for more options.</li><li><code>kwargs</code>: Extra keyword arguments for <code>solve_s_group</code></li></ul><p><strong>How to define groups</strong></p><p>The exported functions <code>hc_partition_groups</code> can be used to build a group  membership vector. </p><p><strong>A note on compute time</strong></p><p>The computational complexity of group knockoffs scales quadratically with group size. Thus, very large groups (e.g. &gt;100 members per group) dramatically slows down  parameter estimation. In such cases, one can consider running the routine  <code>modelX_gaussian_rep_group_knockoffs</code> which constructs group knockoffs by choosing top representatives from each group. </p><p><strong>Reference</strong></p><p>Dai &amp; Barber 2016, The knockoff filter for FDR control in group-sparse and multitask regression</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L47-L93">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Union{String, Symbol}}" href="#Knockoffs.modelX_gaussian_knockoffs-Tuple{AbstractMatrix, Union{String, Symbol}}"><code>Knockoffs.modelX_gaussian_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">modelX_gaussian_knockoffs(X::Matrix, method::Symbol; [m], [covariance_approximator], [kwargs...])
modelX_gaussian_knockoffs(X::Matrix, method::Symbol, μ::Vector, Σ::Matrix; [m], [kwargs...])</code></pre><p>Creates model-free multivariate normal knockoffs by sequentially sampling from  conditional multivariate normal distributions. The true mean <code>μ</code> and covariance <code>Σ</code> is estimated from data if not supplied. </p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> numeric matrix, each row is a sample, and each column is covariate.</li><li><code>method</code>: Can be one of the following<ul><li><code>:mvr</code> for minimum variance-based reconstructability knockoffs (alg 1 in ref 2)</li><li><code>:maxent</code> for maximum entropy knockoffs (alg 2 in ref 2)</li><li><code>:equi</code> for equi-distant knockoffs (eq 2.3 in ref 1), </li><li><code>:sdp</code> for SDP knockoffs (eq 2.4 in ref 1)</li><li><code>:sdp_ccd</code> for SDP knockoffs via coordiate descent (alg 2.2 in ref 3)</li></ul></li><li><code>μ</code>: A <code>p × 1</code> vector of column mean of <code>X</code>, defaults to column mean</li><li><code>Σ</code>: A <code>p × p</code> matrix of covariance of <code>X</code>, defaults to a shrinkage estimator   specified by <code>covariance_approximator</code>. </li><li><code>m</code>: Number of knockoff copies per variable to generate, defaults to 1. </li><li><code>covariance_approximator</code>: A covariance estimator, defaults to <code>LinearShrinkage(DiagonalUnequalVariance(), :lw)</code>   which tends to give good empirical performance when p&gt;n. See CovarianceEstimation.jl for more options.</li><li><code>kwargs...</code>: Possible optional inputs to solvers specified in <code>method</code>, see    <a href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_MVR</code></a>, <a href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_max_entropy</code></a>, and <a href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_sdp_ccd</code></a></li></ul><p><strong>Reference:</strong></p><ol><li>&quot;Panning for Gold: Model-X Knockoffs for High-dimensional Controlled  Variable Selection&quot; by Candes, Fan, Janson, and Lv (2018)</li><li>&quot;Powerful knockoffs via minimizing reconstructability&quot; by Spector, Asher, and Lucas Janson (2020)</li><li>&quot;FANOK: Knockoffs in Linear Time&quot; by Askari et al. (2020).</li></ol><p><strong>Covariance Approximation:</strong></p><p>The covariance is approximated by a linear shrinkage estimator using  Ledoit-Wolf with <code>DiagonalUnequalVariance</code> target,  which seems to perform well for <code>p&gt;n</code> cases. We do not simply use <code>cov(X)</code> since <code>isposdef(cov(X))</code> is typically false. For comparison of various estimators, see: https://mateuszbaran.github.io/CovarianceEstimation.jl/dev/man/msecomp/#msecomp</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/modelX.jl#L1-L38">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.modelX_gaussian_rep_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T" href="#Knockoffs.modelX_gaussian_rep_group_knockoffs-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Union{String, Symbol}, AbstractVector{Int64}}} where T"><code>Knockoffs.modelX_gaussian_rep_group_knockoffs</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">modelX_gaussian_rep_group_knockoffs(X, method, groups; [m], [covariance_approximator], [kwargs...])
modelX_gaussian_rep_group_knockoffs(X, method, groups, μ, Σ; [m], [kwargs...])</code></pre><p>Constructs group knockoffs by choosing representatives from each group and solving a smaller optimization problem based on the representatives only. Remaining knockoffs are generated based on a conditional independence assumption similar to a graphical model (details to be given later). The representatives are computed by <a href="#Knockoffs.choose_group_reps-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}}} where T"><code>choose_group_reps</code></a></p><p><strong>Inputs</strong></p><ul><li><code>X</code>: A <code>n × p</code> design matrix. Each row is a sample, each column is a feature.</li><li><code>method</code>: Method for constructing knockoffs. Options are the same as    <code>modelX_gaussian_group_knockoffs</code></li><li><code>groups</code>: Vector of <code>Int</code> denoting group membership. <code>groups[i]</code> is the group    of <code>X[:, i]</code></li><li><code>covariance_approximator</code>: A covariance estimator, defaults to    <code>LinearShrinkage(DiagonalUnequalVariance(), :lw)</code>. See CovarianceEstimation.jl    for more options.</li><li><code>μ</code>: A length <code>p</code> vector storing the true column means of <code>X</code></li><li><code>Σ</code>: A <code>p × p</code> covariance matrix for columns of <code>X</code></li><li><code>rep_threshold</code>: Value between 0 and 1 that controls the number of    representatives per group. Larger means more representatives (default 0.5)</li><li><code>m</code>: Number of knockoffs per variable, defaults to 1. </li><li><code>kwargs</code>: Extra keyword arguments for <code>solve_s_group</code></li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L129-L154">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.normalize_col!-Tuple{AbstractVecOrMat}" href="#Knockoffs.normalize_col!-Tuple{AbstractVecOrMat}"><code>Knockoffs.normalize_col!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">normalize_col!(X::AbstractVecOrMat, [center=false])</code></pre><p>Normalize each column of <code>X</code> so they sum to 1. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L434-L438">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.prioritize_variants-Tuple{AbstractVector, AbstractVector}" href="#Knockoffs.prioritize_variants-Tuple{AbstractVector, AbstractVector}"><code>Knockoffs.prioritize_variants</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">prioritize_variants!(index::AbstractVector, priority_vars::AbstractVector)</code></pre><p>Given (unsorted) <code>index</code>, we make variables in <code>priority_vars</code> appear first  in <code>index</code>, preserving the original order in <code>index</code> and those not in  <code>priority_vars</code>. </p><p><strong>Example</strong></p><pre><code class="language-julia hljs">index = [11, 4, 5, 9, 7]
priority_vars = [4, 9]
result = prioritize_variants(index, priority_vars)
result == [4, 9, 11, 5, 7]</code></pre></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L2035-L2049">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.rapid-Tuple{AbstractString, AbstractString, AbstractString, Number, AbstractString, Int64, Int64, Int64}" href="#Knockoffs.rapid-Tuple{AbstractString, AbstractString, AbstractString, Number, AbstractString, Int64, Int64, Int64}"><code>Knockoffs.rapid</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">rapid(rapid_exe, vcffile, mapfile, d, outfolder, w, r, s, [a])</code></pre><p>Wrapper for the RaPID program. </p><p><strong>Inputs</strong></p><ul><li><code>rapid_exe</code>: Full path to the <code>RaPID_v.1.7</code> executable file</li><li><code>vcffile</code>: Phased VCF file name</li><li><code>mapfile</code>: Map file name</li><li><code>d</code>: Actual Minimum IBD length in cM</li><li><code>outfolder</code>: Output folder name</li><li><code>w</code>: Number of SNPs in a window for sub-sampling</li><li><code>r</code>: Number of runs</li><li><code>s</code>: Minimum number of successes to consider a hit</li></ul><p><strong>Optional Inputs</strong></p><ul><li><code>a</code>: If <code>true</code>, ignore MAFs. By default (<code>a=false</code>) the sites are selected at random weighted by their MAFs.</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/hmm_wrapper.jl#L12-L29">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.sample_mvn_efficient-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Int64}} where T" href="#Knockoffs.sample_mvn_efficient-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractMatrix{T}, Int64}} where T"><code>Knockoffs.sample_mvn_efficient</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">sample_mvn_efficient(C::AbstractMatrix{T}, D::AbstractMatrix{T}, m::Int)</code></pre><p>Efficiently samples from <code>N(0, A)</code> where</p><p class="math-container">\[\begin{aligned}
A &amp;= \begin{pmatrix}
    C &amp; C-D &amp; \cdots &amp; C-D\\
    C-D &amp; C &amp; \cdots &amp; C-D\\
    \vdots &amp; &amp; \ddots &amp; \vdots\\
    C-D &amp; C-D &amp; &amp; C
\end{pmatrix}
\end{aligned}\]</p><p>Note there are <code>m</code> blocks per row/col</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/ghost.jl#L37-L52">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.search_rank" href="#Knockoffs.search_rank"><code>Knockoffs.search_rank</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">search_rank(A::AbstractMatrix, sk::Vector{Int}, target=0.25, verbose=false)</code></pre><p>Finds the rank (number of columns of A) that best approximates the remaining columns such that regressing each remaining variable on those selected has RSS less than some target. </p><ul><li><code>Σ</code>: Original (p × p) correlation matrix</li><li><code>A</code>: The (upper triangular) cholesky factor of Σ</li><li><code>sk</code>: The (unsorted) columns of A, earlier ones are more important</li><li><code>target</code>: Target residual level</li></ul><p>note: we cannot do binary search because large ranks can increase residuals</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L2100-L2113">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.shift_until_PSD!" href="#Knockoffs.shift_until_PSD!"><code>Knockoffs.shift_until_PSD!</code></a> — <span class="docstring-category">Function</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">shift_until_PSD!(Σ::AbstractMatrix)</code></pre><p>Keeps adding λI to Σ until the minimum eigenvalue &gt; tol</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L422-L426">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.simulate_AR1-Tuple{Int64}" href="#Knockoffs.simulate_AR1-Tuple{Int64}"><code>Knockoffs.simulate_AR1</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">simulate_AR1(p::Int, a=1, b=1, tol=1e-3, max_corr=1, rho=nothing)</code></pre><p>Generates <code>p</code>-dimensional correlation matrix for AR(1) Gaussian process, where successive correlations are drawn from Beta(<code>a</code>,<code>b</code>) independently. If <code>rho</code> is specified, then the process is stationary with correlation <code>rho</code>.</p><p><strong>Source</strong></p><p>https://github.com/amspector100/knockpy/blob/20eddb3eb60e0e82b206ec989cb936e3c3ee7939/knockpy/dgp.py#L61</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L345-L356">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.simulate_ER-Tuple{Int64}" href="#Knockoffs.simulate_ER-Tuple{Int64}"><code>Knockoffs.simulate_ER</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">simulate_ER(p::Int; [invert])</code></pre><p>Simulates a covariance matrix from a clustered Erdos-Renyi graph, which is a block diagonal matrix where each block is an Erdo-Renyi graph. The result is scaled back to a correlation matrix. </p><p>For details, see the 4th simulation routine in section 5.1 of Li and Maathius  https://academic.oup.com/jrsssb/article/83/3/534/7056103?login=false</p><p><strong>Inputs</strong></p><ul><li><code>p</code>: Dimension of covariance matrix</li><li><code>ϕ</code>: Probability of forming an edge between any 2 nodes</li><li><code>lb</code>: lower bound for the value of an edge (drawn from uniform distribution)</li><li><code>ub</code>: upper bound for the value of an edge (drawn from uniform distribution)</li><li><code>invert</code>: Whther to invert the covariance matrix (to obtain the precision)</li><li><code>λmin</code>: minimum eigenvalue of the resulting covariance matrix</li><li><code>blocksize</code>: Number of variables within each ER graph. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L382-L400">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.simulate_block_covariance-Union{Tuple{T}, Tuple{Vector{Int64}, T, T}} where T&lt;:AbstractFloat" href="#Knockoffs.simulate_block_covariance-Union{Tuple{T}, Tuple{Vector{Int64}, T, T}} where T&lt;:AbstractFloat"><code>Knockoffs.simulate_block_covariance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">simulate_block_covariance(groups, ρ, γ, num_v, w)</code></pre><p>Simulates a block covariance matrix similar to the one in <code>Dai &amp; Barber 2016,  The knockoff filter for FDR control in group-sparse and multitask regression</code>.  That is, all diagonal elements will be 1, correlation within groups will be <code>ρ</code>, and correlation between groups will be <code>ρ*γ</code>. </p><p><strong>Inputs</strong></p><ul><li><code>groups</code>: Vector of group membership</li><li><code>ρ</code>: within group correlation </li><li><code>γ</code>: between group correlation</li></ul><p><strong>Optional arguments</strong></p><ul><li><code>num_v</code>: Number of added rank 1 update <code>Σ + v1*v1&#39; + ... + vn*vn&#39;</code> where <code>v</code>    is iid <code>N(0, w)</code> (default 0)</li><li><code>w</code>: variance of the rank 1 update used in <code>num_v</code> (default 1)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L465-L482">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.single_linkage_distance-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Vector{Int64}}} where T" href="#Knockoffs.single_linkage_distance-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Vector{Int64}}} where T"><code>Knockoffs.single_linkage_distance</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">single_linkage_distance(distmat, left, right)</code></pre><p>Computes the minimum distance (i.e. single-linkage distance) between members in <code>left</code> and members in <code>right</code>. Member distances are precomputed in <code>distmat</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1894-L1899">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.single_state_dmc_knockoff!-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractVector{Int64}, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix{T}, Array{T, 3}, AbstractVector{T}, Int64}} where T" href="#Knockoffs.single_state_dmc_knockoff!-Union{Tuple{T}, Tuple{AbstractVector{Int64}, AbstractVector{Int64}, Distributions.Categorical{P, Ps} where {P&lt;:Real, Ps&lt;:AbstractVector{P}}, AbstractMatrix{T}, Array{T, 3}, AbstractVector{T}, Int64}} where T"><code>Knockoffs.single_state_dmc_knockoff!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Samples <code>Zj</code>, the <code>j</code> state of the hidden Markov chain. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/dmc.jl#L93-L95">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_MVR</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_MVR(Σ::AbstractMatrix)</code></pre><p>Solves the minimum variance-based reconstructability problem for fixed-X and model-X knockoffs given correlation matrix Σ. Users should call <code>solve_s</code>  instead of this function. </p><p>See algorithm 1 of &quot;Powerful knockoffs via minimizing  reconstructability&quot; by Spector, Asher, and Lucas Janson (2020) https://arxiv.org/pdf/2011.14625.pdf</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L113-L123">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_SDP-Tuple{AbstractMatrix}" href="#Knockoffs.solve_SDP-Tuple{AbstractMatrix}"><code>Knockoffs.solve_SDP</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_SDP(Σ::AbstractMatrix)</code></pre><p>Solves the SDP problem for fixed-X and model-X knockoffs given correlation matrix Σ.  Users should call <code>solve_s</code> instead of this function. </p><p>The optimization problem is stated in equation 3.13 of https://arxiv.org/pdf/1610.02351.pdf</p><p><strong>Arguments</strong></p><ul><li><code>Σ</code>: A correlation matrix (diagonals all equal to 1)</li><li><code>m</code>: Number of knockoffs to generate, defaults to 1</li><li><code>optm</code>: SDP solver. Defaults to <code>Hypatia.Optimizer(verbose=false)</code>. This can   be any solver that supports the JuMP interface. For example, use    <code>SDPT3.Optimizer</code> in SDPT3.jl package (which is a MATLAB dependency)   for the best performance. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L53-L69">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_equi-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.solve_equi-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_equi</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_equi(Σ::AbstractMatrix)</code></pre><p>Solves the equicorrelated problem for fixed-X and model-X knockoffs given  correlation matrix Σ. Users should call <code>solve_s</code> instead of this function. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L98-L103">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_SDP_single_block-Tuple{AbstractMatrix, AbstractMatrix}" href="#Knockoffs.solve_group_SDP_single_block-Tuple{AbstractMatrix, AbstractMatrix}"><code>Knockoffs.solve_group_SDP_single_block</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_group_SDP_single_block(Σ11, ub)</code></pre><p>Solves a single block of the fully general group SDP problem. The objective is     min  sum_{i,j} |Σ[i,j] - S[i,j]|     s.t. 0 ⪯ S ⪯ A11 - [A12 A13]<em>inv(A22-S2 A32; A23 A33-S3)</em>[A21; A31]</p><p><strong>Inputs</strong></p><ul><li><code>Σ11</code>: The block corresponding to the current group. Must be a correlation matrix. </li><li><code>ub</code>: The matrix defined as A11 - [A12 A13]<em>inv(A22-S2 A32; A23 A33-S3)</em>[A21; A31]</li><li><code>optm</code>: Any solver compatible with JuMP.jl</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L574-L585">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_SDP_subopt-Tuple{AbstractMatrix, Vector{Int64}}" href="#Knockoffs.solve_group_SDP_subopt-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.solve_group_SDP_subopt</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Solves the SDP group knockoff problem using analogy to the equi-correlated group knockoffs. Basically, the idea is to optimize a vector <code>γ</code> where <code>γ[j]</code>  multiplies Σ_jj. In the equi-correlated setting, all <code>γ[j]</code> is forced to be equal.</p><p>Details can be found in Dai &amp; Barber 2016, The knockoff filter for FDR control in group-sparse and multitask regression</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L497-L504">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_block_update-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Union{String, Symbol}}} where T" href="#Knockoffs.solve_group_block_update-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_group_block_update</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p><strong>Todo</strong></p><ul><li>somehow avoid reallocating ub every iteration</li><li>When solving each individual block,<ul><li>warmstart</li><li>avoid reallocating S1_new</li><li>allocate vector of models</li><li>use loose convergence criteria</li></ul></li><li>For singleton groups, don&#39;t use JuMP and directly update</li><li>Currently all objective values are computed based on SDP case.    Need to display objective values for ME/MVR objective</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L687-L698">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_equi-Tuple{AbstractMatrix, Vector{Int64}}" href="#Knockoffs.solve_group_equi-Tuple{AbstractMatrix, Vector{Int64}}"><code>Knockoffs.solve_group_equi</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Solves the equi-correlated group knockoff problem. Here <code>Σ</code> is the true covariance matrix (scaled so that it has 1 on its diagonal) and <code>Σblocks</code> is the block-diagonal covariance matrix where each  block corresponds to groups.</p><p>Details can be found in Dai &amp; Barber 2016, The knockoff filter for FDR control in group-sparse and multitask regression</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L470-L478">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_max_entropy_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T" href="#Knockoffs.solve_group_max_entropy_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_max_entropy_hybrid</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_group_max_entropy_hybrid(Σ, groups, [outer_iter=100], [inner_pca_iter=1],
    [inner_ccd_iter=1], [tol=0.0001], [ϵ=1e-6], [m=1], [robust=false], [verbose=false])</code></pre><p>Solves the group-knockoff optimization problem based on Maximum Entropy objective. Users should call <code>solve_s_group</code> instead of this function. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Correlation matrix</li><li><code>groups</code>: Group membership vector </li></ul><p><strong>Optional inputs</strong></p><ul><li><code>outer_iter</code>: Maximum number of outer iterations. Each outer iteration will   perform <code>inner_pca_iter</code> PCA updates <code>inner_ccd_iter</code> full optimization    updates (default = 100).</li><li><code>inner_pca_iter</code>: Number of full PCA updates before changing to fully   general coordinate descent updates (default = 1)</li><li><code>inner_ccd_iter</code>: Number of full general coordinate descent updates before changing   to PCA updates (default = 1)</li><li><code>tol</code>: convergence tolerance. Algorithm converges when    <code>abs((obj_new-obj_old)/obj_old) &lt; tol</code> OR when changes in <code>S</code> matrix falls    below 1e-4</li><li><code>ϵ</code>: tolerance added to the lower and upper bound, prevents numerical issues   (default = <code>1e-6</code>)</li><li><code>m</code>: Number of knockoffs per variable (defaults <code>1</code>)</li><li><code>robust</code>: whether to use &quot;robust&quot; Cholesky updates. If <code>robust=true</code>, alg will   be ~10x slower, only use this if <code>robust=false</code> causes cholesky updates to fail.   (default <code>false</code>)</li><li><code>verbose</code>: Whether to print intermediate results (default <code>false</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L840-L869">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_mvr_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T" href="#Knockoffs.solve_group_mvr_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_mvr_hybrid</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_group_mvr_hybrid(Σ, groups, [outer_iter=100], [inner_pca_iter=1],
    [inner_ccd_iter=1], [tol=0.0001], [ϵ=1e-6], [m=1], [robust=false], [verbose=false])</code></pre><p>Solves the group-knockoff optimization problem based on MVR objective. Users should call <code>solve_s_group</code> instead of this function. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Correlation matrix</li><li><code>groups</code>: Group membership vector </li></ul><p><strong>Optional inputs</strong></p><ul><li><code>outer_iter</code>: Maximum number of outer iterations. Each outer iteration will   perform <code>inner_pca_iter</code> PCA updates <code>inner_ccd_iter</code> full optimization    updates (default = 100).</li><li><code>inner_pca_iter</code>: Number of full PCA updates before changing to fully   general coordinate descent updates (default = 1)</li><li><code>inner_ccd_iter</code>: Number of full general coordinate descent updates before changing   to PCA updates (default = 1)</li><li><code>tol</code>: convergence tolerance. Algorithm converges when    <code>abs((obj_new-obj_old)/obj_old) &lt; tol</code> OR when changes in <code>S</code> matrix falls    below 1e-4</li><li><code>ϵ</code>: tolerance added to the lower and upper bound, prevents numerical issues   (default = <code>1e-6</code>)</li><li><code>m</code>: Number of knockoffs per variable (defaults <code>1</code>)</li><li><code>robust</code>: whether to use &quot;robust&quot; Cholesky updates. If <code>robust=true</code>, alg will   be ~10x slower, only use this if <code>robust=false</code> causes cholesky updates to fail.   (default <code>false</code>)</li><li><code>verbose</code>: Whether to print intermediate results (default <code>false</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L1027-L1056">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_group_sdp_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T" href="#Knockoffs.solve_group_sdp_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>Knockoffs.solve_group_sdp_hybrid</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_group_sdp_hybrid(Σ, groups, [outer_iter=100], [inner_pca_iter=1],
    [inner_ccd_iter=1], [tol=0.0001], [ϵ=1e-6], [m=1], [robust=false], [verbose=false])</code></pre><p>Solves the group-knockoff optimization problem based on SDP objective. Users should call <code>solve_s_group</code> instead of this function. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Correlation matrix</li><li><code>groups</code>: Group membership vector </li></ul><p><strong>Optional inputs</strong></p><ul><li><code>outer_iter</code>: Maximum number of outer iterations. Each outer iteration will   perform <code>inner_pca_iter</code> PCA updates <code>inner_ccd_iter</code> full optimization    updates (default = 100).</li><li><code>inner_pca_iter</code>: Number of full PCA updates before changing to fully   general coordinate descent updates (default = 1)</li><li><code>inner_ccd_iter</code>: Number of full general coordinate descent updates before changing   to PCA updates (default = 1)</li><li><code>tol</code>: convergence tolerance. Algorithm converges when    <code>abs((obj_new-obj_old)/obj_old) &lt; tol</code> OR when changes in <code>S</code> matrix falls    below 1e-4</li><li><code>ϵ</code>: tolerance added to the lower and upper bound, prevents numerical issues   (default = <code>1e-6</code>)</li><li><code>m</code>: Number of knockoffs per variable (defaults <code>1</code>)</li><li><code>robust</code>: whether to use &quot;robust&quot; Cholesky updates. If <code>robust=true</code>, alg will   be ~10x slower, only use this if <code>robust=false</code> causes cholesky updates to fail.   (default <code>false</code>)</li><li><code>verbose</code>: Whether to print intermediate results (default <code>false</code>)</li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L921-L950">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_max_entropy</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_max_entropy(Σ::AbstractMatrix)</code></pre><p>Solves the maximum entropy knockoff problem for fixed-X and model-X knockoffs given correlation matrix Σ. Users should call <code>solve_s</code> instead of this function. </p><p><strong>Reference</strong></p><p>Algorithm 2.2 from Powerful Knockoffs via Minimizing Reconstructability: https://arxiv.org/pdf/2011.14625.pdf</p><p><strong>Note</strong></p><p>There is a typo in algorithm for computing ME knockoffs in &quot;Powerful knockoffs via minimizing reconstructability&quot; by Spector, Asher, and Lucas Janson (2020). In the supplemental section, equation 59, they needed to evaluate  <code>c_m = D^t_{-j,j}D^{-1}_{-j,-j}D_{-j,j}</code>. They claimed the FANOK paper  (&quot;FANOK: KNOCKOFFS IN LINEAR TIME&quot; by Askari et al. (2020)) implies that <code>c_m = ||v_m||^2</code> where <code>Lv_m = u</code>. However, according to section A.1.2 of the FANOK paper, it seems like the actual update should be <code>D^t_{-j,j}D^{-1}_{-j,-j}D_{-j,j} = ζ*||c_m||^2 / (ζ + ||c_m||^2)</code>  where <code>ζ = 2Σ_{jj} - s_j</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L201-L220">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_s-Tuple{LinearAlgebra.Symmetric, Union{String, Symbol}}" href="#Knockoffs.solve_s-Tuple{LinearAlgebra.Symmetric, Union{String, Symbol}}"><code>Knockoffs.solve_s</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_s(Σ::Symmetric, method::Symbol; m=1, kwargs...)</code></pre><p>Solves the vector <code>s</code> for generating knockoffs. <code>Σ</code> can be a general  covariance matrix but it must be wrapped in the <code>Symmetric</code> keyword. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: A covariance matrix (one must wrap <code>Symmetric(Σ)</code> explicitly)</li><li><code>method</code>: Can be one of the following<ul><li><code>:mvr</code> for minimum variance-based reconstructability knockoffs (alg 1 in ref 2)</li><li><code>:maxent</code> for maximum entropy knockoffs (alg 2 in ref 2)</li><li><code>:equi</code> for equi-distant knockoffs (eq 2.3 in ref 1), </li><li><code>:sdp</code> for SDP knockoffs (eq 2.4 in ref 1)</li><li><code>:sdp_ccd</code> fast SDP knockoffs via coordiate descent (alg 2.2 in ref 3)</li></ul></li><li><code>m</code>: Number of knockoffs per variable, defaults to 1. </li><li><code>kwargs</code>: Extra arguments available for specific methods. For example, to use    less stringent convergence tolerance for MVR knockoffs, specify <code>tol = 0.001</code>.   For a list of available options, see <a href="#Knockoffs.solve_MVR-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_MVR</code></a>,   <a href="#Knockoffs.solve_max_entropy-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_max_entropy</code></a>, <a href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_sdp_ccd</code></a>, <a href="#Knockoffs.solve_SDP-Tuple{AbstractMatrix}"><code>solve_SDP</code></a>, or   <a href="#Knockoffs.solve_equi-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>solve_equi</code></a></li></ul><p><strong>Reference</strong></p><ol><li>&quot;Controlling the false discovery rate via Knockoffs&quot; by Barber and Candes (2015).</li><li>&quot;Powerful knockoffs via minimizing reconstructability&quot; by Spector, Asher, and Lucas Janson (2020)</li><li>&quot;FANOK: Knockoffs in Linear Time&quot; by Askari et al. (2020).</li></ol></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L1-L26">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_s_graphical_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), AbstractVector{Int64}, AbstractVector{Int64}, Union{String, Symbol}}} where T" href="#Knockoffs.solve_s_graphical_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), AbstractVector{Int64}, AbstractVector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_s_graphical_group</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_s_graphical_group(Σ::Symmetric, groups::Vector{Int}, group_reps::Vector{Int},
method; [m], [verbose])</code></pre><p>Solves the group knockoff problem but the convex optimization problem only runs on the representatives. The non-representative variables are assumed to be  independent by groups when conditioning on the reprensetatives. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: Symmetric <code>p × p</code> covariance matrix</li><li><code>groups</code>: <code>p</code> dimensional vector of group membership</li><li><code>group_reps</code>: Indices for the representatives. </li><li><code>method</code>: Method for solving group knockoff problem</li><li><code>m</code>: Number of knockoffs to generate per feature</li><li><code>verbose</code>: Whether to print informative intermediate results</li><li><code>kwargs...</code>: extra arguments for <a href="#Knockoffs.solve_s_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}, Union{String, Symbol}}} where T"><code>solve_s_group</code></a></li></ul><p><strong>Outputs</strong></p><ul><li><code>S</code>: Matrix obtained from solving the optimization problem on the representatives.</li><li><code>D</code>: A <code>p × p</code> (dense) matrix corresponding to the S matrix for both the   representative and non-representative variables. Knockoff sampling should    use this matrix. If the graphical conditional independent assumption is    satisfied exactly, this matrix should be sparse, but it is always never sparse   unless we use <code>cond_indep_corr</code> to force the covariance matrix to satisify it. </li><li><code>obj</code>: Objective value for solving the optimization problem on the representatives. </li></ul></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L239-L264">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_s_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}, Union{String, Symbol}}} where T" href="#Knockoffs.solve_s_group-Union{Tuple{T}, Tuple{LinearAlgebra.Symmetric{T, S} where S&lt;:(AbstractMatrix{&lt;:T}), Vector{Int64}, Union{String, Symbol}}} where T"><code>Knockoffs.solve_s_group</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_s_group(Σ, groups, method; [m=1], kwargs...)</code></pre><p>Solves the group knockoff problem, returns block diagonal matrix S satisfying <code>(m+1)/m*Σ - S ⪰ 0</code> where <code>m</code> is number of knockoffs per feature. </p><p><strong>Inputs</strong></p><ul><li><code>Σ</code>: A general covariance matrix wrapped by <code>Symmetric</code> keyword</li><li><code>groups</code>: Vector of group membership, does not need to be contiguous</li><li><code>method</code>: Method for constructing knockoffs. Options include<ul><li><code>:maxent</code>: (recommended) for fully general maximum entropy group knockoffs</li><li><code>:mvr</code>: for fully general minimum variance-based reconstructability (MVR) group    knockoffs</li><li><code>:equi</code>: for equi-correlated knockoffs. This is the methodology proposed in   <code>Dai R, Barber R. The knockoff filter for FDR control in group-sparse and multitask regression.    International conference on machine learning 2016 Jun 11 (pp. 1851-1859). PMLR.</code></li><li><code>:sdp</code>: Fully general SDP group knockoffs based on coodinate descent</li><li><code>:sdp_subopt</code>: Chooses each block <code>S_{i} = γ_i * Σ_{ii}</code>. This slightly    generalizes the equi-correlated group knockoff idea proposed in Dai and Barber 2016.</li><li><code>:sdp_block</code>: Fully general SDP group knockoffs where each block is solved exactly    using an interior point solver. </li></ul></li><li><code>m</code>: Number of knockoffs per variable, defaults to 1. </li><li><code>kwargs</code>: Extra arguments available for specific methods. For example, to use    less stringent convergence tolerance, specify <code>tol = 0.001</code>.   For a list of available options, see <a href="#Knockoffs.solve_group_mvr_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>solve_group_mvr_hybrid</code></a>,   <a href="#Knockoffs.solve_group_max_entropy_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>solve_group_max_entropy_hybrid</code></a>, <a href="#Knockoffs.solve_group_sdp_hybrid-Union{Tuple{T}, Tuple{AbstractMatrix{T}, Vector{Int64}}} where T"><code>solve_group_sdp_hybrid</code></a>, or   <a href="#Knockoffs.solve_group_equi-Tuple{AbstractMatrix, Vector{Int64}}"><code>solve_group_equi</code></a></li></ul><p><strong>Output</strong></p><ul><li><code>S</code>: A matrix solved so that <code>(m+1)/m*Σ - S ⪰ 0</code> and <code>S ⪰ 0</code></li><li><code>γ</code>: A vector that is only non-empty for equi and suboptimal knockoff constructions.    They correspond to values of γ where <code>S_{gg} = γΣ_{gg}</code>. So for equi, the   vector is length 1. For SDP, the vector has length equal to number of groups</li><li><code>obj</code>: Final SDP/MVR/ME objective value given <code>S</code>. Equi-correlated group knockoffs   and singleton (non-grouped knockoffs) returns 0 because they either no objective    value or it is not necessary to evaluate the objectives</li></ul><p><strong>Warning</strong></p><p>This function potentially permutes the columns/rows of <code>Σ</code>, and puts them back at the end. Thus one should NOT call <code>solve_s_group</code> on the same <code>Σ</code> simultaneously, e.g. in a multithreaded for loop. Permutation does not happen when groups are contiguous. </p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/group.jl#L305-L347">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T" href="#Knockoffs.solve_sdp_ccd-Union{Tuple{AbstractMatrix{T}}, Tuple{T}} where T"><code>Knockoffs.solve_sdp_ccd</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">solve_sdp_ccd(Σ::AbstractMatrix)</code></pre><p>Solves the SDP problem for fixed-X and model-X knockoffs using coordinate descent,  given correlation matrix Σ. Users should call <code>solve_s</code> instead of this function. </p><p><strong>Reference</strong></p><p>Algorithm 2.2 from &quot;FANOK: Knockoffs in Linear Time&quot; by Askari et al. (2020).</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/utilities.jl#L282-L290">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.threshold-Union{Tuple{T}, Tuple{AbstractVector{T}, Number}, Tuple{AbstractVector{T}, Number, Any}, Tuple{AbstractVector{T}, Number, Any, Int64}} where T&lt;:AbstractFloat" href="#Knockoffs.threshold-Union{Tuple{T}, Tuple{AbstractVector{T}, Number}, Tuple{AbstractVector{T}, Number, Any}, Tuple{AbstractVector{T}, Number, Any, Int64}} where T&lt;:AbstractFloat"><code>Knockoffs.threshold</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">threshold(w::AbstractVector, q::Number, [method=:knockoff], [m::Int=1])</code></pre><p>Chooses a threshold τ &gt; 0 by choosing <code>τ</code> to be one of the following τ = min{ t &gt; 0 : {#j: w[j] ≤ -t} / {#j: w[j] ≥ t} ≤ q }        (<code>method=:knockoff</code>) τ = min{ t &gt; 0 : (1 + {#j: w[j] ≤ -t}) / {#j: w[j] ≥ t} ≤ q }  (<code>method=:knockoff</code>)</p><p><strong>Inputs</strong></p><ul><li><code>w</code>: Vector of feature important statistics</li><li><code>q</code>: target FDR (between 0 and 1)</li><li><code>method</code>: either <code>:knockoff</code> or <code>:knockoff_plus</code> (default)</li><li><code>rej_bounds</code>: Number of values of top W to consider (default = 10000)</li></ul><p><strong>Reference:</strong></p><p>Equation 3.10 (<code>method=:knockoff</code>) or 3.11 (<code>method=:knockoff_plus</code>) of  &quot;Panning for Gold: Model-X Knockoffs for High-dimensional Controlled Variable Selection&quot; by Candes, Fan, Janson, and Lv (2018)</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/threshold.jl#L1-L18">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.update_normalizing_constants!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64, Any}} where T&lt;:AbstractFloat" href="#Knockoffs.update_normalizing_constants!-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64}, Tuple{AbstractMatrix{T}, AbstractVector{Int64}, AbstractVector{Int64}, Array{T, 3}, AbstractVector{T}, Int64, Any}} where T&lt;:AbstractFloat"><code>Knockoffs.update_normalizing_constants!</code></a> — <span class="docstring-category">Method</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><pre><code class="language-julia hljs">update_normalizing_constants!(Q::AbstractMatrix{T}, q::AbstractVector{T})</code></pre><p>Computes normalizing constants recursively using equation (5).</p><p><strong>Inputs</strong></p><ul><li><code>Q</code>: <code>K × K × p</code> array. <code>Q[:, :, j]</code> is a <code>K × K</code> matrix of transition   probabilities for <code>j</code>th state, i.e. Q[l, k, j] = P(X<em>{j} = k | X</em>{j - 1} = l).   The first transition matrix is not used. </li><li><code>q</code>: <code>K × 1</code> vector of initial probabilities</li></ul><p><strong>todo: efficiency</strong></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/experimental/dmc.jl#L48-L60">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.Knockoff" href="#Knockoffs.Knockoff"><code>Knockoffs.Knockoff</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>A <code>Knockoff</code> holds the original design matrix <code>X</code>, along with its knockoff <code>Xko</code>.</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/struct.jl#L1-L3">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.KnockoffFilter" href="#Knockoffs.KnockoffFilter"><code>Knockoffs.KnockoffFilter</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>A <code>KnockoffFilter</code> is essentially a <code>Knockoff</code> that has gone through a feature  selection procedure, such as the Lasso. It stores, among other things, the final estimated parameters <code>beta</code> after applying the knockoff-filter procedure.</p><p>The <code>debiased</code> variable is a boolean indicating whether estimated effect size have been debiased with Lasso. The <code>W</code> vector stores the feature importance statistic that satisfies the flip coin  property. <code>tau</code> is the knockoff threshold, which controls the empirical FDR at  level <code>q</code></p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/struct.jl#L105-L115">source</a></section></article><article class="docstring"><header><a class="docstring-article-toggle-button fa-solid fa-chevron-down" href="javascript:;" title="Collapse docstring"></a><a class="docstring-binding" id="Knockoffs.MarkovChainTable" href="#Knockoffs.MarkovChainTable"><code>Knockoffs.MarkovChainTable</code></a> — <span class="docstring-category">Type</span><span class="is-flex-grow-1 docstring-article-toggle-button" title="Collapse docstring"></span></header><section><div><p>Genotype states are index pairs (ka, kb) where ka, kb is unordered haplotype 1 and 2.  If there are K=5 haplotype motifs, then the 15 possible genotype states and their index are</p><p>(1, 1) = 1 (1, 2) = 2     (2, 2) = 6 (1, 3) = 3     (2, 3) = 7     (3, 3) = 10 (1, 4) = 4     (2, 4) = 8     (3, 4) = 11     (4, 4) = 13 (1, 5) = 5     (2, 5) = 9     (3, 5) = 12     (4, 5) = 14     (5, 5) = 15</p></div><a class="docs-sourcelink" target="_blank" href="https://github.com/biona001/Knockoffs.jl/blob/3021e490b69bc6a23ce09fa7930cbec052e6bd05/src/struct.jl#L72-L81">source</a></section></article></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../JuliaCall/">« Calling from R/Python</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.8.0 on <span class="colophon-date" title="Friday 20 December 2024 02:47">Friday 20 December 2024</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
