<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Group Knockoffs Â· Knockoffs.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Knockoffs.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><a class="tocitem" href="../fixed/fixed/">Fixed-X Knockoffs</a></li><li><a class="tocitem" href="../modelX/modelX/">Model-X Knockoffs</a></li><li class="is-active"><a class="tocitem" href>Group Knockoffs</a><ul class="internal"><li><a class="tocitem" href="#Gaussian-model-X-group-knockoffs-with-known-mean-and-covariance"><span>Gaussian model-X group knockoffs with known mean and covariance</span></a></li><li><a class="tocitem" href="#Define-group-memberships"><span>Define group memberships</span></a></li><li><a class="tocitem" href="#Generating-group-knockoffs"><span>Generating group knockoffs</span></a></li><li><a class="tocitem" href="#Second-order-group-knockoffs"><span>Second order group knockoffs</span></a></li><li><a class="tocitem" href="#Representative-group-knockoffs"><span>Representative group knockoffs</span></a></li><li><a class="tocitem" href="#Lasso-Example"><span>Lasso Example</span></a></li><li><a class="tocitem" href="#Conclusion"><span>Conclusion</span></a></li></ul></li><li><a class="tocitem" href="../knockoffscreen/knockoffscreen/">KnockoffScreen Knockoffs</a></li><li><a class="tocitem" href="../ghost_knockoffs/">Ghost Knockoffs</a></li><li><a class="tocitem" href="../hmm/hmm/">HMM Knockoffs</a></li><li><a class="tocitem" href="../ipad/">IPAD Knockoffs</a></li><li><a class="tocitem" href="../JuliaCall/">Calling from R</a></li><li><a class="tocitem" href="../api/">API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Group Knockoffs</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Group Knockoffs</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/biona001/Knockoffs.jl/blob/master/docs/src/man/group.md" title="Edit on GitHub"><span class="docs-icon fab">ï‚›</span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="Group-Knockoffs"><a class="docs-heading-anchor" href="#Group-Knockoffs">Group Knockoffs</a><a id="Group-Knockoffs-1"></a><a class="docs-heading-anchor-permalink" href="#Group-Knockoffs" title="Permalink"></a></h1><p>This tutorial generates group (model-X) knockoffs, which is useful when predictors are highly correlated. The methodology is described in the following paper</p><blockquote><p>Dai R, Barber R. The knockoff filter for FDR control in group-sparse and multitask regression. InInternational conference on machine learning 2016 Jun 11 (pp. 1851-1859). PMLR.</p></blockquote><div class="admonition is-info"><header class="admonition-header">Note</header><div class="admonition-body"><p>In the original paper, Dai and Barber only describes how to construct a suboptimal equi-correlated group knockoffs. Here we implement fully generalized alternatives.</p></div></div><p>Currently available options for group knockoffs:</p><ul><li><code>:maxent</code>: Fully general maximum entropy (maxent) group knockoff, based on coordinate descent.</li><li><code>:mvr</code>: Fully general minimum variance-based reconstructability (MVR) group knockoff, based on coordinate descent.</li><li><code>:sdp</code>: Fully general SDP group knockoffs, based on coordinate descent. In general MVR/ME knockoffs tends to perform better than SDP in terms of power, and SDP generally converges slower. </li><li><code>:equi</code>: This implements the equi-correlated idea proposed in <a href="https://proceedings.mlr.press/v48/daia16.html">Barber and Dai</a>, which lets <span>$S_j = \gamma \Sigma_{(G_j, G_j)}$</span> where <span>$\Sigma_{(G_j, G_j)}$</span> is the block of <span>$\Sigma$</span> containing variables in the <span>$j$</span>th group. Thus, instead of optimizing over all variables in <span>$S$</span>, we optimize a scalar <span>$\gamma$</span>. Conveniently, there a simple closed form solution for <span>$\gamma$</span>. For <code>mvr</code> and <code>maxent</code> group knockoffs, we initialize <span>$S$</span> using this construction. </li><li><code>:sdp_subopt</code>: This generalizes the equi-correlated group knockoff idea by having <span>$S_j = \gamma_j \Sigma_{(G_j, G_j)}$</span>. Instead of optimizing over all variables in <span>$S$</span>, we optimize over a vector <span>$\gamma_1,...,\gamma_G$</span>. Note this functionality is mainly provided for testing purposes. </li></ul><pre><code class="language-julia hljs"># load packages for this tutorial
using Knockoffs
using LinearAlgebra
using Random
using StatsKit
using ToeplitzMatrices
using Distributions</code></pre><pre><code class="nohighlight hljs">[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mPrecompiling StatsKit [2cb19f9e-ec4d-5c53-8573-a4542a68d3f0]
[32mMinimizing 2 	 Time: 0:00:00 (88.81 ms/it)[39m[K
[32mMinimizing 57 	 Time: 0:00:00 ( 4.06 ms/it)[39m[K
[32mMinimizing 34 	 Time: 0:00:00 ( 2.97 ms/it)[39m[K
[32mMinimizing 119 	 Time: 0:00:00 ( 1.72 ms/it)[39m[K
[32mMinimizing 203 	 Time: 0:00:00 ( 1.51 ms/it)[39m[K
[32mMinimizing 222 	 Time: 0:00:00 ( 1.48 ms/it)[39m[K
[36m[1m[ [22m[39m[36m[1mInfo: [22m[39mPrecompiling ToeplitzMatrices [c751599d-da0a-543b-9d20-d0a503d91d24]</code></pre><h2 id="Gaussian-model-X-group-knockoffs-with-known-mean-and-covariance"><a class="docs-heading-anchor" href="#Gaussian-model-X-group-knockoffs-with-known-mean-and-covariance">Gaussian model-X group knockoffs with known mean and covariance</a><a id="Gaussian-model-X-group-knockoffs-with-known-mean-and-covariance-1"></a><a class="docs-heading-anchor-permalink" href="#Gaussian-model-X-group-knockoffs-with-known-mean-and-covariance" title="Permalink"></a></h2><p>To illustrate, lets simulate data <span>$\mathbf{X}$</span> with covariance <span>$\Sigma$</span> and mean <span>$\mu$</span>. Our model is</p><p class="math-container">\[\begin{aligned}
    X_{p \times 1} \sim N(\mathbf{0}_p, \Sigma)
\end{aligned}\]</p><p>where</p><p class="math-container">\[\begin{aligned}
\Sigma = 
\begin{pmatrix}
    1 &amp; \rho &amp; \rho^2 &amp; ... &amp; \rho^p\\
    \rho &amp; 1 &amp; &amp; ... &amp; \rho^{p-1}\\
    \vdots &amp; &amp; &amp; 1 &amp; \vdots \\
    \rho^p &amp; \cdots &amp; &amp; &amp; 1
\end{pmatrix}
\end{aligned}\]</p><p>Given <span>$n$</span> iid samples from the above distribution, we will generate knockoffs according to </p><p class="math-container">\[\begin{aligned}
(X, \tilde{X}) \sim N
\left(0, \ 
\begin{pmatrix}
    \Sigma &amp; \Sigma - diag(s)\\
    \Sigma - diag(s) &amp; \Sigma
\end{pmatrix}
\right)
\end{aligned}\]</p><p>Because variables are highly correlated with its neighbors (<span>$\rho = 0.9$</span>), it becomes difficult to distinguish which among a bunch of highly correlated variables are truly causal. Thus, group knockoffs test whether a <em>group</em> of variables have any signal should have better power than standard (single-variable) knockoffs. </p><p>First, lets simulate some data</p><pre><code class="language-julia hljs"># simulate data
Random.seed!(2023)
n = 250 # sample size
p = 500 # number of features
k = 10  # number of causal variables
Î£ = Matrix(SymmetricToeplitz(0.9.^(0:(p-1))))
# Î£ = simulate_AR1(p, a=3, b=1)
# Î£ = simulate_block_covariance(groups, 0.75, 0.25)
Î¼ = zeros(p)
L = cholesky(Î£).L
X = randn(n, p) * L # design matrix
zscore!(X, mean(X, dims=1), std(X, dims=1)); # standardize columns of X</code></pre><h2 id="Define-group-memberships"><a class="docs-heading-anchor" href="#Define-group-memberships">Define group memberships</a><a id="Define-group-memberships-1"></a><a class="docs-heading-anchor-permalink" href="#Define-group-memberships" title="Permalink"></a></h2><p>To generate group knockoffs, we need to vector specifying group membership. One can define this vector manually, or use the built-in functions <a href="https://biona001.github.io/Knockoffs.jl/dev/man/api/#Knockoffs.hc_partition_groups"><code>hc_partition_groups</code></a> or <a href="https://biona001.github.io/Knockoffs.jl/dev/man/api/#Knockoffs.id_partition_groups"><code>id_partition_groups</code></a>. </p><pre><code class="language-julia hljs">groups = hc_partition_groups(X, cutoff = 0.5)</code></pre><pre><code class="nohighlight hljs">500-element Vector{Int64}:
  1
  1
  1
  2
  2
  2
  2
  3
  3
  3
  3
  3
  4
  â‹®
 93
 93
 93
 93
 94
 94
 94
 95
 95
 96
 96
 96</code></pre><h2 id="Generating-group-knockoffs"><a class="docs-heading-anchor" href="#Generating-group-knockoffs">Generating group knockoffs</a><a id="Generating-group-knockoffs-1"></a><a class="docs-heading-anchor-permalink" href="#Generating-group-knockoffs" title="Permalink"></a></h2><p>Generate group knockoffs with the exported function <a href="https://biona001.github.io/Knockoffs.jl/dev/man/api/#Knockoffs.modelX_gaussian_group_knockoffs"><code>modelX_gaussian_group_knockoffs</code></a>. Similar to non-group knockoffs, group knockoff accepts keyword arguments <code>m</code>, <code>tol</code>, <code>method</code>, and <code>verbose</code> which controls the algorithm&#39;s behavior. </p><pre><code class="language-julia hljs">@time me = modelX_gaussian_group_knockoffs(
    X, :maxent, groups, Î¼, Î£, 
    m = 5,              # number of knockoffs per variable to generate
    tol = 0.001,        # convergence tolerance
    inner_ccd_iter = 1, # optimize every entry of S exactly 1 time before moving on to PCA updates
    inner_pca_iter = 1, # optimize S with respect to pre-computed eigenvectors 1 time before going to CCA updates
    verbose=true);      # whether to print informative intermediate results</code></pre><pre><code class="nohighlight hljs">Maxent initial obj = -12356.34252838294
Iter 1 (PCA): obj = -8052.261406317257, Î´ = 0.08590802942739141, t1 = 0.02, t2 = 0.06
Iter 2 (CCD): obj = -7794.572748302033, Î´ = 0.021168745196021455, t1 = 0.06, t2 = 0.22, t3 = 0.0
Iter 3 (PCA): obj = -7511.5813673898, Î´ = 0.05161131551931233, t1 = 0.08, t2 = 0.28
Iter 4 (CCD): obj = -7461.192156067138, Î´ = 0.012741504093028197, t1 = 0.11, t2 = 0.44, t3 = 0.0
Iter 5 (PCA): obj = -7338.12850904518, Î´ = 0.04789239342203643, t1 = 0.13, t2 = 0.5
Iter 6 (CCD): obj = -7308.932874229322, Î´ = 0.010536044596001392, t1 = 0.17, t2 = 0.73, t3 = 0.0
Iter 7 (PCA): obj = -7229.540018465826, Î´ = 0.036888999559287, t1 = 0.32, t2 = 0.81
Iter 8 (CCD): obj = -7208.676126818758, Î´ = 0.0093200457247459, t1 = 0.36, t2 = 0.99, t3 = 0.0
Iter 9 (PCA): obj = -7154.410518552632, Î´ = 0.03082171235011954, t1 = 0.38, t2 = 1.05
Iter 10 (CCD): obj = -7137.772110915227, Î´ = 0.008537926721557176, t1 = 0.41, t2 = 1.21, t3 = 0.01
Iter 11 (PCA): obj = -7099.327854453767, Î´ = 0.031361095723232424, t1 = 0.43, t2 = 1.27
Iter 12 (CCD): obj = -7085.247398507873, Î´ = 0.007935922476527326, t1 = 0.46, t2 = 1.43, t3 = 0.01
Iter 13 (PCA): obj = -7057.140483805416, Î´ = 0.0329120543668779, t1 = 0.48, t2 = 1.49
Iter 14 (CCD): obj = -7044.876172687189, Î´ = 0.0073148711066542684, t1 = 0.51, t2 = 1.65, t3 = 0.01
Iter 15 (PCA): obj = -7023.629304760571, Î´ = 0.03250775080424135, t1 = 0.53, t2 = 1.72
Iter 16 (CCD): obj = -7012.850120947548, Î´ = 0.006854890650307496, t1 = 0.56, t2 = 1.88, t3 = 0.01
Iter 17 (PCA): obj = -6996.2718588537, Î´ = 0.03073822907867497, t1 = 0.58, t2 = 1.94
Iter 18 (CCD): obj = -6986.792631541138, Î´ = 0.00643070491605296, t1 = 0.61, t2 = 2.1, t3 = 0.01
Iter 19 (PCA): obj = -6973.531686161966, Î´ = 0.028115057674247466, t1 = 0.63, t2 = 2.16
Iter 20 (CCD): obj = -6965.156942284143, Î´ = 0.006029270847764364, t1 = 0.66, t2 = 2.33, t3 = 0.01
Iter 21 (PCA): obj = -6954.364877631307, Î´ = 0.025782754495081224, t1 = 0.68, t2 = 2.38
Iter 22 (CCD): obj = -6946.941292530272, Î´ = 0.0056444702455843545, t1 = 0.71, t2 = 2.55, t3 = 0.01
Iter 23 (PCA): obj = -6938.050251132212, Î´ = 0.023339824851938744, t1 = 0.74, t2 = 2.61
Iter 24 (CCD): obj = -6931.429620290803, Î´ = 0.005272863979624524, t1 = 0.77, t2 = 2.77, t3 = 0.02
Iter 25 (PCA): obj = -6924.038356243489, Î´ = 0.020838710472615027, t1 = 0.78, t2 = 2.83
Iter 26 (CCD): obj = -6918.112876107202, Î´ = 0.004918165386397138, t1 = 0.81, t2 = 2.99, t3 = 0.02
Iter 27 (PCA): obj = -6911.905927691633, Î´ = 0.01859000844736733, t1 = 0.83, t2 = 3.05
Iter 28 (CCD): obj = -6906.577950472116, Î´ = 0.004577091626964406, t1 = 0.86, t2 = 3.21, t3 = 0.02
 19.578308 seconds (65.69 M allocations: 3.483 GiB, 4.39% gc time, 77.76% compilation time)</code></pre><ul><li>Here CCD corresponds to optimization each entry <span>$S_{ij}$</span> independently, while PCA is a faster update that updates <span>$S_{new} = S + \delta vv&#39;$</span>. </li><li>Users can modify the default behavior by supplying the arguments <code>inner_pca_iter</code> and <code>inner_ccd_iter</code>. For instance, we can turn off <code>inner_ccd_iter</code> to achieve much faster convergence at the sacrifice small accuracy. </li><li><span>$t_1, t_2, t_3$</span> are timers, which reveals that the computational bottleneck is in (2), which we dispatch to efficient LAPACK libraries, so the overall performance of our algorithm cannot really be improved. <ol><li><span>$t_1$</span>: updating cholesky factors</li><li><span>$t_2$</span>: solving forward-backward equations</li><li><span>$t_3$</span>: solving off-diagonal 1D optimization problems using Brent&#39;s method</li></ol></li></ul><p>The output is a struct with the following fields</p><pre><code class="language-julia hljs">struct GaussianGroupKnockoff{T&lt;:AbstractFloat, BD&lt;:AbstractMatrix, S&lt;:Symmetric} &lt;: Knockoff
    X::Matrix{T} # n Ã— p design matrix
    Xko::Matrix{T} # n Ã— mp matrix storing knockoffs of X
    groups::Vector{Int} # p Ã— 1 vector of group membership
    S::BD # p Ã— p block-diagonal matrix of the same size as Sigma. S and (m+1)/m*Sigma - S are both psd
    gammas::Vector{T} # for suboptimal group construction only. These are scalars chosen so that S_i = Î³_i * Sigma_i
    m::Int # number of knockoffs per feature generated
    Sigma::S # p Ã— p symmetric covariance matrix. 
    method::Symbol # method for solving s
    obj::T # final objective value of group knockoff
end</code></pre><p>Given this result, lets do a sanity check: is <span>$(m+1)/m\Sigma - S$</span> positive semi-definite?</p><pre><code class="language-julia hljs">m = 5
eigmin((m+1)/m*me.Sigma - me.S)</code></pre><pre><code class="nohighlight hljs">0.007406506932664477</code></pre><h2 id="Second-order-group-knockoffs"><a class="docs-heading-anchor" href="#Second-order-group-knockoffs">Second order group knockoffs</a><a id="Second-order-group-knockoffs-1"></a><a class="docs-heading-anchor-permalink" href="#Second-order-group-knockoffs" title="Permalink"></a></h2><p>In practice, we often do not have the true covariance matrix <span>$\Sigma$</span> and the true means <span>$\mu$</span>. In that case, we can generate second order group knockoffs via the 3 argument function</p><pre><code class="language-julia hljs">me_second_order = modelX_gaussian_group_knockoffs(X, :maxent, groups);</code></pre><p>This will estimate the covariance matrix via a shrinkage estimator, see documentation API for more details. </p><h2 id="Representative-group-knockoffs"><a class="docs-heading-anchor" href="#Representative-group-knockoffs">Representative group knockoffs</a><a id="Representative-group-knockoffs-1"></a><a class="docs-heading-anchor-permalink" href="#Representative-group-knockoffs" title="Permalink"></a></h2><p>One can choose a few representatives from each group and generate <em>representative</em> group knockoffs, with the following advantage:</p><ul><li>Dramatically improved computational efficiency, since the group-knockoff optimization problem only needs to be carried out on the representative variables.</li><li>Improved power over standard group knockoffs, since the exchangeability have to be satisfied for less variables, so the resulting knockoffs are more &quot;flexible&quot;</li></ul><p>This model assume that conditional on the group representatives, remaining variables are independent by groups. Although this assumption is not always met, we find that group-FDR is never really violated in our experiments with real or simulated data. </p><pre><code class="language-julia hljs">@time rME = modelX_gaussian_rep_group_knockoffs(
    X, :maxent, groups, Î¼, Î£, 
    m = 5,               # number of knockoffs per variable to generate
    tol = 0.0001,        # convergence tolerance
    rep_threshold = 0.8, # R2 threshold for choosing representatives
    verbose=true);       # whether to print informative intermediate results</code></pre><pre><code class="nohighlight hljs">100 representatives for 500 variables, 108 optimization variables
Maxent initial obj = -1251.9504482429606
Iter 1 (PCA): obj = -779.3679715355898, Î´ = 0.396729400414175, t1 = 0.0, t2 = 0.0
Iter 2 (CCD): obj = -775.060406275815, Î´ = 0.0732451631869636, t1 = 0.0, t2 = 0.0, t3 = 0.0
Iter 3 (PCA): obj = -742.0320684018326, Î´ = 0.35854568776631224, t1 = 0.0, t2 = 0.0
Iter 4 (CCD): obj = -742.0051586067349, Î´ = 0.005820330294768541, t1 = 0.0, t2 = 0.0, t3 = 0.0
Iter 5 (PCA): obj = -740.2381969308991, Î´ = 0.06132916410588748, t1 = 0.0, t2 = 0.0
Iter 6 (CCD): obj = -740.2377890912246, Î´ = 0.0007984668584872479, t1 = 0.0, t2 = 0.0, t3 = 0.0
Iter 7 (PCA): obj = -739.5557857700379, Î´ = 0.027095277708548027, t1 = 0.0, t2 = 0.0
Iter 8 (CCD): obj = -739.5554840270346, Î´ = 0.0006939533604367249, t1 = 0.0, t2 = 0.0, t3 = 0.0
Iter 9 (PCA): obj = -739.364132913859, Î´ = 0.014219568405133007, t1 = 0.0, t2 = 0.0
Iter 10 (CCD): obj = -739.3640794172708, Î´ = 0.00026751205521428727, t1 = 0.0, t2 = 0.0, t3 = 0.0
Iter 11 (PCA): obj = -739.3004784935146, Î´ = 0.00699480271009976, t1 = 0.0, t2 = 0.0
Iter 12 (CCD): obj = -739.3004578732453, Î´ = 0.00021513370749886738, t1 = 0.0, t2 = 0.0, t3 = 0.0
  0.255370 seconds (20.49 k allocations: 219.477 MiB)</code></pre><p>Note that the resulting knockoffs are still <span>$n \times mp$</span>, so we do sample knockoffs for each variable even though the optimization was only carried out on a subset.</p><pre><code class="language-julia hljs">rME.Xko</code></pre><pre><code class="nohighlight hljs">250Ã—2500 Matrix{Float64}:
 -2.02635    -1.7701      -1.46708     â€¦   1.14117    1.3035      1.51521
 -0.473473   -0.00353028  -0.446125       -1.43538   -1.61465    -1.0251
 -0.434336   -1.23647     -1.25906        -0.6267    -0.272594   -0.431613
  1.56359     0.278573     0.671124        0.630377   0.579558    1.0876
  0.387161    0.856616     1.44796        -0.760866  -0.748318   -0.495847
 -0.791019   -0.98869     -0.396516    â€¦   1.6927     0.214687   -0.125589
  1.26676     0.361408     0.194175       -0.823221  -0.99416    -0.529763
  0.0446295  -0.0775493   -0.0545377      -0.143951  -0.243873    0.138882
 -1.43764    -1.35191     -1.47821         0.372513   0.147667    0.263357
 -0.445685   -0.409486    -0.117022       -0.539456  -0.979681   -1.13224
 -1.12771    -0.895357    -0.875399    â€¦  -0.428835  -0.722677   -0.0963992
  3.24501     1.87553      1.4093          0.225577  -0.482896   -0.58531
 -0.406158   -0.104083    -0.208398       -1.58035   -1.28124    -1.07925
  â‹®                                    â‹±                         
  0.0744866  -0.12148     -0.506796        2.27877    1.59647     1.08393
 -0.639735   -0.0899262   -0.682674        2.26979    2.36776     1.23767
 -0.743036   -0.078543     0.190691    â€¦   0.280561   0.683024    0.604584
  0.216802   -0.235232    -0.583439       -1.14196   -0.837435   -1.26028
  1.39833     0.642316     0.752464       -2.25555   -2.05632    -1.58866
 -1.35121    -1.18921     -1.48731         1.83777    1.85815     1.37793
  0.0421617   0.0257475    0.00332313      0.120749  -0.126425   -0.245098
 -0.257331   -0.0124215    0.259443    â€¦  -0.228297  -0.260701   -0.571025
  2.36186     1.48677      1.10764         0.599617   0.888141    0.566555
 -2.95162    -1.58974     -1.50044         0.488967   0.510731   -0.0708063
  1.8735      1.90576      1.54649         0.263684  -0.0619415   0.573829
 -1.31383    -0.977912    -2.02039         1.34478    0.644186    0.77451</code></pre><h2 id="Lasso-Example"><a class="docs-heading-anchor" href="#Lasso-Example">Lasso Example</a><a id="Lasso-Example-1"></a><a class="docs-heading-anchor-permalink" href="#Lasso-Example" title="Permalink"></a></h2><p>Lets see the empirical power and FDR group knockoffs over 10 simulations when</p><ul><li>the targer FDR is 10%</li><li>we generate <span>$m=5$</span> knockoffs per feature</li><li><span>$\beta_j \sim \pm 0.25$</span> for 10 causal <span>$j$</span>s</li></ul><p>Note power and FDR is defined at the group level</p><pre><code class="language-julia hljs">group_powers, group_fdrs, group_times, group_s = Float64[], Float64[], Float64[], Float64[]

Random.seed!(2022)
for sim in 1:10
    # simulate X
    Random.seed!(sim)
    n = 1000 # sample size
    p = 200  # number of covariates
    k = 10   # number of true predictors
    Î£ = Matrix(SymmetricToeplitz(0.9.^(0:(p-1)))) # true covariance matrix
    Î¼ = zeros(p)
    L = cholesky(Î£).L
    X = randn(n, p) * L
    zscore!(X, mean(X, dims=1), std(X, dims=1)); # standardize columns of X

    # define groups
    groups = hc_partition_groups(X, cutoff=0.5)
    
    # simulate y
    Î²true = zeros(p)
    Î²true[1:k] .= rand(-1:2:1, k) .* 0.25
    shuffle!(Î²true)
    correct_groups = groups[findall(!iszero, Î²true)] |&gt; unique
    Ïµ = randn(n)
    y = X * Î²true + Ïµ;

    # group ME knockoffs
    t = @elapsed ko_filter = fit_lasso(y, X, method=:maxent, groups=groups, m=5)
    selected = ko_filter.selected[3]
    power = length(intersect(correct_groups, selected)) / length(correct_groups)
    fdr = length(setdiff(selected, correct_groups)) / max(1, length(selected))
    println(&quot;Sim $sim group-knockoff power = $power, FDR = $fdr, time=$t&quot;)
    push!(group_powers, power); push!(group_fdrs, fdr); push!(group_times, t)
    GC.gc();GC.gc();GC.gc();
end

println(&quot;\nME group knockoffs have average group power $(mean(group_powers))&quot;)
println(&quot;ME group knockoffs have average group FDR $(mean(group_fdrs))&quot;)
println(&quot;ME group knockoffs took average $(mean(group_times)) seconds&quot;);</code></pre><pre><code class="nohighlight hljs">Sim 1 group-knockoff power = 1.0, FDR = 0.1, time=9.395477167
Sim 2 group-knockoff power = 0.7777777777777778, FDR = 0.0, time=8.08905475
Sim 3 group-knockoff power = 0.8888888888888888, FDR = 0.1111111111111111, time=6.093907333
Sim 4 group-knockoff power = 0.8, FDR = 0.0, time=8.676211084
Sim 5 group-knockoff power = 0.7, FDR = 0.0, time=10.33491675
Sim 6 group-knockoff power = 0.5, FDR = 0.0, time=10.055918625
Sim 7 group-knockoff power = 1.0, FDR = 0.0, time=6.909068458
Sim 8 group-knockoff power = 0.4444444444444444, FDR = 0.0, time=9.819233042
Sim 9 group-knockoff power = 0.7, FDR = 0.0, time=11.155753209
Sim 10 group-knockoff power = 0.5555555555555556, FDR = 0.0, time=7.340749875

ME group knockoffs have average group power 0.7366666666666667
ME group knockoffs have average group FDR 0.021111111111111112
ME group knockoffs took average 8.7870290293 seconds</code></pre><p>For comparison, lets try the same simulation but we generate regular (non-grouped) knockoffs</p><pre><code class="language-julia hljs">regular_powers, regular_fdrs, regular_times = Float64[], Float64[], Float64[]

Random.seed!(2022)
for sim in 1:10
    # simulate X
    Random.seed!(sim)
    n = 1000 # sample size
    p = 200  # number of covariates
    k = 10   # number of true predictors
    Î£ = Matrix(SymmetricToeplitz(0.9.^(0:(p-1)))) # true covariance matrix
    Î¼ = zeros(p)
    L = cholesky(Î£).L
    X = randn(n, p) * L
    zscore!(X, mean(X, dims=1), std(X, dims=1)); # standardize columns of X
    
    # simulate y
    Î²true = zeros(p)
    Î²true[1:k] .= rand(-1:2:1, k) .* 0.25
    shuffle!(Î²true)
    correct_snps = findall(!iszero, Î²true)
    Ïµ = randn(n)
    y = X * Î²true + Ïµ;

    # group ME knockoffs
    t = @elapsed ko_filter = fit_lasso(y, X, method=:maxent, m=5)
    selected = ko_filter.selected[3]
    power = length(intersect(correct_snps, selected)) / length(correct_snps)
    fdr = length(setdiff(selected, correct_snps)) / max(1, length(selected))
    println(&quot;Sim $sim nongroup-knockoff power = $power, FDR = $fdr, time=$t&quot;)
    push!(regular_powers, power); push!(regular_fdrs, fdr); push!(regular_times, t)
    GC.gc();GC.gc();GC.gc();
end

println(&quot;\nME (standard) knockoffs have average group power $(mean(regular_powers))&quot;)
println(&quot;ME (standard) knockoffs have average group FDR $(mean(regular_fdrs))&quot;)
println(&quot;ME (standard) knockoffs took average $(mean(regular_times)) seconds&quot;);</code></pre><pre><code class="nohighlight hljs">Sim 1 nongroup-knockoff power = 0.7, FDR = 0.2222222222222222, time=7.151643042
Sim 2 nongroup-knockoff power = 0.7, FDR = 0.0, time=7.163531958
Sim 3 nongroup-knockoff power = 0.2, FDR = 0.0, time=5.438854459
Sim 4 nongroup-knockoff power = 0.0, FDR = 0.0, time=7.861218583
Sim 5 nongroup-knockoff power = 0.2, FDR = 0.0, time=9.57650625
Sim 6 nongroup-knockoff power = 0.0, FDR = 0.0, time=8.987028709
Sim 7 nongroup-knockoff power = 0.0, FDR = 0.0, time=5.27945125
Sim 8 nongroup-knockoff power = 0.0, FDR = 0.0, time=9.898184792
Sim 9 nongroup-knockoff power = 0.4, FDR = 0.0, time=10.721144208
Sim 10 nongroup-knockoff power = 0.5, FDR = 0.0, time=6.266258084

ME (standard) knockoffs have average group power 0.26999999999999996
ME (standard) knockoffs have average group FDR 0.02222222222222222
ME (standard) knockoffs took average 7.8343821335 seconds</code></pre><h2 id="Conclusion"><a class="docs-heading-anchor" href="#Conclusion">Conclusion</a><a id="Conclusion-1"></a><a class="docs-heading-anchor-permalink" href="#Conclusion" title="Permalink"></a></h2><ul><li>When variables are highly correlated so that one cannot find exact discoveries, group knockoffs may be useful for improving power as it identifies whether a group of variables are non-null without having to pinpoint the exact discovery. It trades resolution to discover more causal signals.</li><li>Group knockoffs control the group FDR to be below the target FDR level. </li><li>Groups do not have to be contiguous</li><li>With modest group sizes, group knockoff&#39;s compute time is roughly equivalent to standard (non-grouped) knockoffs</li><li>When <span>$p$</span> is too large or group sizes are too large, one can employ representative group knockoff strategy. Empirically it has better power and much faster compute times. </li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../modelX/modelX/">Â« Model-X Knockoffs</a><a class="docs-footer-nextpage" href="../knockoffscreen/knockoffscreen/">KnockoffScreen Knockoffs Â»</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 9 August 2023 02:28">Wednesday 9 August 2023</span>. Using Julia version 1.8.5.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
